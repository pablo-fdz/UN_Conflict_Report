{
    "section_split": {
        "split_pattern": "(?m)^## (.+?)\\s*\\n(.*?)(?=^## |\\Z)"
    },
    "accuracy_evaluation": {
        "base_claims_prompt": "You are an AI tasked with extracting verifiable claims from a section of a report. A verifiable claim is an atomic statement that can be checked for accuracy and is relevant to the topic of the report. Here is an example:\nSection: \"The constant attacks of Group A and Group B on civilians in Country X have led to a high number of casualties as well as internally displaced persons (IDPs). In May 2025, there have been more IDPs than any other month that year.\"\n\nFrom this section, you can extract the following verifiable claims:\n1. \"Group A has been carrying constant attacks on civilians in Country X.\"\n2. \"Group B has been carrying constant attacks on civilians in Country X.\"\n3. \"In May 2025, there have been more IDPs than in any of the previous months of 2025.\"\n\nNotes on this:\n- Claims 1 and 2 have to be separate claims, because they refer to different groups, so one could be true while the other is false and that would make the first sentence incorrect.\n- The claim in the original section about a \"high number of casualties\" is not verifiable, because it is not quantifiable/specific. We do not know what \"high\" means and we do not have a reference to compare it too. Claims that are subjective or vague should not be extracted.\n- It is important that you always make all the necessary information explicit in the claims, without pronouns or terms that make references to previous sentences, so that each claim is self-contained and can be verified independently.\n- Also, when abbreviations of any kind are used, always include, if you know it with certainty, the full name/term plus the abbreviation in parentheses.\n\nYou must extract all verifiable claims from the following section of a report:\nSection: \"{section_text}\"",
        "base_questions_prompt": "You are a journalist tasked with evaluating the accuracy of a set of claims against a knowledge base.\nFor the given list of claims below, you must generate 1 to 4 questions aimed at leading you to the information needed to verify each claim.\nEach question should be specific, clear, and concise, designed to have a closed-ended objective answer.\n\nWhen abbreviations of any kind are used in the claim, always include in the question, if you know it with certainty, the full name/term plus the abbreviation in parentheses.\n\nHere is the list of claims:\n{claims_list}.",
        "base_eval_prompt": "You are an expert fact-checker. Your task is to evaluate a claim based on a set of questions and their corresponding answers, as well as a list of previously verified true claims. The answers are generated from a knowledge base. Based on all the information provided, determine if the claim is true, false, or a mixture of true and false.\n\n- **true**: The provided information fully supports the claim. The claim can also be considered true if it can be logically inferred from the previously verified true claims.\n- **false**: The provided information explicitly contradicts the claim.\n- **mixture**: The provided information partially supports the claim, supports some parts but not others, or is insufficient to make a full determination.\n\nHere is the claim and the supporting information:\n\n**Claim to Evaluate:**\n\"{claim_text}\"\n\n**Questions and Answers for the Claim:**\n{questions_and_answers_json}\n\n**Previously Verified True Claims (for context):**\n{previously_true_claims}\n\n",
        "llm_claims_config": {
            "model_name": "gemini-2.5-flash-lite-preview-06-17",
            "model_params": {
                "temperature": 0.0,
                "response_mime_type": "application/json"
            },
            "max_requests_per_minute": 15
        },
        "llm_questions_config": {
            "model_name": "gemini-2.5-flash-lite-preview-06-17",
            "model_params": {
                "temperature": 1.0,
                "response_mime_type": "application/json"
            },
            "max_requests_per_minute": 15
        },
        "llm_evaluator_config": {
                "model_name": "gemini-2.5-flash-lite-preview-06-17",
                "model_params": {
                    "temperature": 0.0,
                    "response_mime_type": "application/json"
                },
            "max_requests_per_minute": 15
            }
    },
    "retrievers": {
        "VectorRetriever": {
            "enabled": false,
            "return_properties": [
                "text"
            ],
            "search_params": {
                "top_k": 5
            }
        },
        "VectorCypherRetriever": {
            "enabled": false,
            "retrieval_query": "//1) Go out 2-3 hops in the entity graph and get relationships\nWITH node AS chunk\nMATCH (chunk)<-[:FROM_CHUNK]-()-[relList:!FROM_CHUNK]-{1,2}()\nUNWIND relList AS rel\n\n//2) collect relationships and text chunks\nWITH collect(DISTINCT chunk) AS chunks,\n collect(DISTINCT rel) AS rels\n\n//3) format and return context\nRETURN '=== text ===\\n' + apoc.text.join([c in chunks | c.text], '\\n---\\n') + '\\n\\n=== kg_rels ===\\n' +\n apoc.text.join([r in rels | startNode(r).name + ' - ' + type(r) + '(' + coalesce(r.details, '') + ')' +  ' -> ' + endNode(r).name ], '\\n---\\n') AS info",
            "search_params": {
                "top_k": 5
            }
        },
        "HybridRetriever": {
            "enabled": false,
            "return_properties": [
                "text"
            ],
            "search_params": {
                "top_k": 5,
                "ranker": "linear",
                "alpha": 0.5
            }
        },
        "HybridCypherRetriever": {
            "enabled": true,
            "retrieval_query": "//1) Go out 2-3 hops in the entity graph and get relationships\nWITH node AS chunk\nMATCH (chunk)<-[:FROM_CHUNK]-()-[relList:!FROM_CHUNK]-{1,2}()\nUNWIND relList AS rel\n\n//2) collect relationships and text chunks\nWITH collect(DISTINCT chunk) AS chunks,\n collect(DISTINCT rel) AS rels\n\n//3) format and return context\nRETURN '=== text ===\\n' + apoc.text.join([c in chunks | c.text], '\\n---\\n') + '\\n\\n=== kg_rels ===\\n' +\n apoc.text.join([r in rels | startNode(r).name + ' - ' + type(r) + '(' + coalesce(r.details, '') + ')' +  ' -> ' + endNode(r).name ], '\\n---\\n') AS info",
            "search_params": {
                    "top_k": 5,
                    "ranker": "linear",
                    "alpha": 0.5
            }
        }
    },
    "graphrag": {
        "llm_config": {
            "model_name": "gemini-2.5-flash-lite-preview-06-17",
            "model_params": {
                "temperature": 0.0,
                "response_mime_type": "application/json"
            },
            "max_requests_per_minute": 15
        },
        "rag_template_config": {
            "template": "# Question:\n{query_text}\n \n# Context:\n{context}\n \n# Examples:\n{examples}\n \n# Answer:\n",
            "system_instructions": "Answer the Question using the following Context. Only respond with information mentioned in the Context. Do not inject any speculative information not mentioned. If no examples are provided, omit the Examples section in your answer."
        },
        "query_text": "Using the provided `Context` below, answer the following questions about the `Claim`. Answer concisely and truthfully, without making assumptions or adding information beyond what is provided in the `Context`. If there is not enough information in the `Context` to answer a question, state that by answering with \"Not enough information to answer this question.\".\n\nHere is the claim and the questions:\nClaim: {claim}\nQuestions: {questions}",
        "examples": "Claim: \"The UN has reported a significant increase in the number of internally displaced persons (IDPs) in Country X due to ongoing conflicts.\"\nQuestions: [\"What is the current number of IDPs in Country X?\", \"What are the main causes of the increase in IDPs in Country X?\", \"How does the current situation compare to previous years?\"]\n\nExample output: {\"What is the current number of IDPs in Country X?\": \"Not enough information to answer this question.\", \"What are the main causes of the increase in IDPs in Country X?\": \"Ongoing conflicts and violence.\", \"How does the current situation compare to previous years?\": \"There has been a significant increase compared to previous years.\"}",
        "return_context": true
    }
}