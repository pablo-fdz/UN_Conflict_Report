{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a022a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import neo4j\n",
    "from neo4j_graphrag_custom.kg_indexer import KGIndexer\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdad93",
   "metadata": {},
   "source": [
    "# 0. Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60857c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration and setup\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# script_dir = os.path.dirname(os.path.abspath(__file__))  # Uncomment if running as a script\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "dotenv_path = os.path.join(script_dir, '.env')\n",
    "load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "# Open configuration file from JSON format\n",
    "config_path = os.path.join(script_dir, 'kg_building_config.json')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Neo4j connection\n",
    "neo4j_uri = os.getenv('NEO4J_URI')\n",
    "neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "driver = neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb699fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = KGIndexer(driver=driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38422a15",
   "metadata": {},
   "source": [
    "# 1. Vector index\n",
    "\n",
    "Index on the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c109d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector index 'embeddings_index' created successfully.\n",
      "Vector index 'embeddings_index' exists with the following details:\n",
      "<Record name='text_embeddings' type='VECTOR' entityType='NODE' labelsOrTypes=['Chunk'] properties=['embedding'] options={'indexProvider': 'vector-2.0', 'indexConfig': {'vector.hnsw.m': 16, 'vector.hnsw.ef_construction': 100, 'vector.dimensions': 384, 'vector.similarity_function': 'COSINE', 'vector.quantization.enabled': True}}>\n"
     ]
    }
   ],
   "source": [
    "# Get the dimensions from the SentenceTransformer model\n",
    "try:\n",
    "    model = SentenceTransformer(f'sentence-transformers/{config['embedder_config']['model_name']}')  # Load the model\n",
    "    embedding_dim = model.get_sentence_embedding_dimension()  # Get the embedding dimension dynamically (only if using SentenceTransformer models!)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}. Try using a SentenceTransformer model.\")\n",
    "\n",
    "index_name = \"embeddings_index\"\n",
    "\n",
    "indexer.create_vector_index(\n",
    "    index_name=index_name,  # Name of the index\n",
    "    label=\"Chunk\",  # Node label to index\n",
    "    embedding_property=\"embedding\",  # Name of the node specified in \"label\" containing the embeddings\n",
    "    dimensions=embedding_dim,  # Dimensions of the embeddings, dynamically set from the model\n",
    ")\n",
    "\n",
    "# Check if the index was created successfully\n",
    "indexer.retrieve_vector_index_info(\n",
    "    index_name=index_name,  # Name of the index to retrieve information about\n",
    "    label_or_type=\"Chunk\",  # Node label or relationship type to check for the index\n",
    "    embedding_property=\"embedding\"  # Name of the property containing the embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e751737",
   "metadata": {},
   "source": [
    "# 2. Full text index\n",
    "\n",
    "Index on the actual texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3177372b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text index 'fulltext_index' created successfully.\n",
      "Full text index 'fulltext_index' exists with the following details:\n",
      "<Record name='fulltext_index' type='FULLTEXT' entityType='NODE' labelsOrTypes=['Chunk'] properties=['text'] options={'indexProvider': 'fulltext-1.0', 'indexConfig': {'fulltext.analyzer': 'standard-no-stop-words', 'fulltext.eventually_consistent': False}}>\n"
     ]
    }
   ],
   "source": [
    "index_name = \"fulltext_index\"\n",
    "\n",
    "indexer.create_fulltext_index(\n",
    "    index_name=index_name,  # Name of the index\n",
    "    label=\"Chunk\",  # Node label to index\n",
    "    node_properties=[\"text\"]  # Name of the node specified in \"label\" containing the full text\n",
    ")\n",
    "\n",
    "# Check if the index was created successfully\n",
    "indexer.retrieve_fulltext_index_info(\n",
    "    index_name=index_name,  # Name of the index to retrieve information about\n",
    "    label_or_type=\"Chunk\",  # Node label or relationship type to check for the index\n",
    "    text_properties=[\"text\"]  # Name of the property containing the full text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0ad5b",
   "metadata": {},
   "source": [
    "# 3. List existing indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8850fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 indexes in the database:\n",
      "\n",
      "1. {'id': 2, 'name': '__entity__id', 'state': 'ONLINE', 'populationPercent': 100.0, 'type': 'RANGE', 'entityType': 'NODE', 'labelsOrTypes': ['__KGBuilder__'], 'properties': ['id'], 'indexProvider': 'range-1.0', 'owningConstraint': None, 'lastRead': neo4j.time.DateTime(2025, 6, 4, 8, 32, 21, 581000000, tzinfo=<UTC>), 'readCount': 498}\n",
      "\n",
      "2. {'id': 0, 'name': 'index_343aff4e', 'state': 'ONLINE', 'populationPercent': 100.0, 'type': 'LOOKUP', 'entityType': 'NODE', 'labelsOrTypes': None, 'properties': None, 'indexProvider': 'token-lookup-1.0', 'owningConstraint': None, 'lastRead': neo4j.time.DateTime(2025, 6, 4, 8, 32, 21, 733000000, tzinfo=<UTC>), 'readCount': 6}\n",
      "\n",
      "3. {'id': 1, 'name': 'index_f7700477', 'state': 'ONLINE', 'populationPercent': 100.0, 'type': 'LOOKUP', 'entityType': 'RELATIONSHIP', 'labelsOrTypes': None, 'properties': None, 'indexProvider': 'token-lookup-1.0', 'owningConstraint': None, 'lastRead': None, 'readCount': 0}\n",
      "\n",
      "Existing indexes:\n",
      "[{'id': 2, 'name': '__entity__id', 'state': 'ONLINE', 'populationPercent': 100.0, 'type': 'RANGE', 'entityType': 'NODE', 'labelsOrTypes': ['__KGBuilder__'], 'properties': ['id'], 'indexProvider': 'range-1.0', 'owningConstraint': None, 'lastRead': neo4j.time.DateTime(2025, 6, 4, 8, 32, 21, 581000000, tzinfo=<UTC>), 'readCount': 498}, {'id': 0, 'name': 'index_343aff4e', 'state': 'ONLINE', 'populationPercent': 100.0, 'type': 'LOOKUP', 'entityType': 'NODE', 'labelsOrTypes': None, 'properties': None, 'indexProvider': 'token-lookup-1.0', 'owningConstraint': None, 'lastRead': neo4j.time.DateTime(2025, 6, 4, 8, 32, 21, 733000000, tzinfo=<UTC>), 'readCount': 6}, {'id': 1, 'name': 'index_f7700477', 'state': 'ONLINE', 'populationPercent': 100.0, 'type': 'LOOKUP', 'entityType': 'RELATIONSHIP', 'labelsOrTypes': None, 'properties': None, 'indexProvider': 'token-lookup-1.0', 'owningConstraint': None, 'lastRead': None, 'readCount': 0}]\n"
     ]
    }
   ],
   "source": [
    "existing_indexes = indexer.list_all_indexes()\n",
    "\n",
    "print(\"\\nExisting indexes:\")\n",
    "print(existing_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c167d",
   "metadata": {},
   "source": [
    "# 4. Dropping indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a78b6b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fulltext_index', 'text_embeddings']\n",
      "Dropping index: fulltext_index\n",
      "Index 'fulltext_index' dropped if it existed.\n",
      "Dropping index: text_embeddings\n",
      "Index 'text_embeddings' dropped if it existed.\n"
     ]
    }
   ],
   "source": [
    "# Select the created indexes to drop\n",
    "indexes_to_drop = [index['name'] for index in existing_indexes if index['name'] in [\"text_embeddings\", \"fulltext_index\"]]\n",
    "print(indexes_to_drop)\n",
    "\n",
    "# Drop the specified indexes if they exist\n",
    "for index in indexes_to_drop:\n",
    "    print(f\"Dropping index: {index}\")\n",
    "    indexer.drop_index_if_exists(index_name=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdcd125",
   "metadata": {},
   "source": [
    "# 5. Closing the driver connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706cbc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
