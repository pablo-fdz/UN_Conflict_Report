{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae0c9b",
   "metadata": {},
   "source": [
    "# 0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2a8341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory (graphrag_pipeline) to the Python path (needed for importing\n",
    "# modules in parent directory)\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Utilities\n",
    "import asyncio\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from library.kg_builder import CustomKGPipeline, build_kg_from_df\n",
    "from library.kg_builder.utilities import GeminiLLM\n",
    "from neo4j_graphrag.experimental.components.resolver import (\n",
    "    SpaCySemanticMatchResolver, FuzzyMatchResolver, SinglePropertyExactMatchResolver\n",
    ")\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "# Neo4j and Neo4j GraphRAG imports\n",
    "import neo4j\n",
    "from neo4j_graphrag.embeddings import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182b7fc",
   "metadata": {},
   "source": [
    "Let's first check the available Gemini models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03b114e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='models/embedding-gecko-001' display_name='Embedding Gecko' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1024 output_token_limit=1 supported_actions=['embedText', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.0-pro-vision-latest' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-pro-vision' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-latest' display_name='Gemini 1.5 Pro Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-002' display_name='Gemini 1.5 Pro 002' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro' display_name='Gemini 1.5 Pro' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-latest' display_name='Gemini 1.5 Flash Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash' display_name='Gemini 1.5 Flash' description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-002' display_name='Gemini 1.5 Flash 002' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b' display_name='Gemini 1.5 Flash-8B' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-001' display_name='Gemini 1.5 Flash-8B 001' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-latest' display_name='Gemini 1.5 Flash-8B Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-03-25' display_name='Gemini 2.5 Pro Preview 03-25' description='Gemini 2.5 Pro Preview 03-25' version='2.5-preview-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-04-17' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-05-20' display_name='Gemini 2.5 Flash Preview 05-20' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-05-20' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash' display_name='Gemini 2.5 Flash' description='Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-04-17-thinking' display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-lite-preview-06-17' display_name='Gemini 2.5 Flash-Lite Preview 06-17' description='Preview release (June 11th, 2025) of Gemini 2.5 Flash-Lite' version='2.5-preview-06-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-05-06' display_name='Gemini 2.5 Pro Preview 05-06' description='Preview release (May 6th, 2025) of Gemini 2.5 Pro' version='2.5-preview-05-06' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-06-05' display_name='Gemini 2.5 Pro Preview' description='Preview release (June 5th, 2025) of Gemini 2.5 Pro' version='2.5-preview-06-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro' display_name='Gemini 2.5 Pro' description='Stable release (June 17th, 2025) of Gemini 2.5 Pro' version='2.5' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-exp' display_name='Gemini 2.0 Flash Experimental' description='Gemini 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash' display_name='Gemini 2.0 Flash' description='Gemini 2.0 Flash' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-001' display_name='Gemini 2.0 Flash 001' description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-001' display_name='Gemini 2.0 Flash-Lite 001' description='Stable version of Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite' display_name='Gemini 2.0 Flash-Lite' description='Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-preview-02-05' display_name='Gemini 2.0 Flash-Lite Preview 02-05' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-preview' display_name='Gemini 2.0 Flash-Lite Preview' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-pro-exp' display_name='Gemini 2.0 Pro Experimental' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-pro-exp-02-05' display_name='Gemini 2.0 Pro Experimental 02-05' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-exp-1206' display_name='Gemini Experimental 1206' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp-01-21' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp-1219' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-tts' display_name='Gemini 2.5 Flash Preview TTS' description='Gemini 2.5 Flash Preview TTS' version='gemini-2.5-flash-exp-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=16384 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-tts' display_name='Gemini 2.5 Pro Preview TTS' description='Gemini 2.5 Pro Preview TTS' version='gemini-2.5-pro-preview-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=16384 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/learnlm-2.0-flash-experimental' display_name='LearnLM 2.0 Flash Experimental' description='LearnLM 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=32768 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-1b-it' display_name='Gemma 3 1B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-4b-it' display_name='Gemma 3 4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-12b-it' display_name='Gemma 3 12B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-27b-it' display_name='Gemma 3 27B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3n-e4b-it' display_name='Gemma 3n E4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3n-e2b-it' display_name='Gemma 3n E2B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/embedding-001' display_name='Embedding 001' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/text-embedding-004' display_name='Text Embedding 004' description='Obtain a distributed representation of a text.' version='004' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-embedding-exp-03-07' display_name='Gemini Embedding Experimental 03-07' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-embedding-exp' display_name='Gemini Embedding Experimental' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/aqa' display_name='Model that performs Attributed Question Answering.' description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=7168 output_token_limit=1024 supported_actions=['generateAnswer'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/imagen-3.0-generate-002' display_name='Imagen 3.0 002 model' description='Vertex served Imagen 3.0 002 model' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/imagen-4.0-generate-preview-06-06' display_name='Imagen 4 (Preview)' description='Vertex served Imagen 4.0 model' version='01' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/imagen-4.0-ultra-generate-preview-06-06' display_name='Imagen 4 Ultra (Preview)' description='Vertex served Imagen 4.0 ultra model' version='01' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/veo-2.0-generate-001' display_name='Veo 2' description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-native-audio-dialog' display_name='Gemini 2.5 Flash Preview Native Audio Dialog' description='Gemini 2.5 Flash Preview Native Audio Dialog' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-exp-native-audio-thinking-dialog' display_name='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' description='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' version='gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-live-001' display_name='Gemini 2.0 Flash 001' description='Gemini 2.0 Flash 001' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['bidiGenerateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-live-2.5-flash-preview' display_name='Gemini Live 2.5 Flash Preview' description='Gemini Live 2.5 Flash Preview' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['bidiGenerateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if gemini_api_key:\n",
    "    client = genai.Client(api_key=gemini_api_key)  # Configure the API key for genai\n",
    "else:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable is not set.\")\n",
    "\n",
    "# Display available models\n",
    "for model in client.models.list():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad2805",
   "metadata": {},
   "source": [
    "We also have to make sure that the corresponding SpaCy model for text embedding used at the resolving step is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43270dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'en_core_web_lg' is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "def ensure_spacy_model(model_name):\n",
    "    if importlib.util.find_spec(model_name) is None:\n",
    "        print(f\"Model '{model_name}' not found. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", model_name])\n",
    "    else:\n",
    "        print(f\"Model '{model_name}' is already installed.\")\n",
    "\n",
    "# Use it for 'en_core_web_lg'\n",
    "ensure_spacy_model(\"en_core_web_lg\")  # Model used for resolving entities in the KG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a20a0a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_default': False,\n",
       " 'template': 'You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph that will be used for creating security reports for different countries.\\n\\nExtract the entities (nodes) and specify their type, location, affiliation, severity, etc. from the Input text.nThe text describes a security incident. The text contains names of the following entitites: Country, State, Town, Location of the incident, Actors.\\nThe text also contains additional data like Actors affiliations, severity of the incident, number of fatalities, type of event - store these details as node properties.\\nAlso extract the relationships between these nodes. The relationship direction goes from the start node to the end node.\\n\\nReturn result as JSON using the following format:\\n{{\"nodes\": [ {{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {{\"name\": \"name of entity\", \"type\": \"type of node\", \"location\": \"location, town, state, country that the node is associated with\" }} }}],\\n\"relationships\": [{{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"details\": \"Description of the relationship\"}} }}] }}\\n\\n- Use only the information from the Input text. Do not create edges between nodes and chunks when the relationship is not clear enough.\\n\\nUse only the following nodes and relationships (if provided):\\n{schema}\\n\\nAssign a unique ID (string) to each node, and reuse it to define relationships.\\nDo not return any additional information other than the JSON in it.\\n\\nExamples:\\n{examples}\\n\\nInput text:\\n{text}'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_files_path = os.path.join(os.path.dirname(os.getcwd()), 'config_files')\n",
    "\n",
    "with open(os.path.join(config_files_path, 'kg_building_config.json'), 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config['prompt_template_config']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39afcd",
   "metadata": {},
   "source": [
    "# 1. Loading the data\n",
    "\n",
    "The data is loaded here as a reference, but it is loaded again inside the pipeline below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4320d1",
   "metadata": {},
   "source": [
    "## 1.2. Factal sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d29a4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use parent_dir to construct the absolute path to the data file\n",
    "file_path = os.path.join(parent_dir, 'data', 'factal', 'Factal_Sudan_2025-06-01_2025-06-28.parquet')\n",
    "\n",
    "# Check if file exists before reading\n",
    "if os.path.exists(file_path):\n",
    "\tdf1 = pl.read_parquet(file_path)\n",
    "\tdf1 = df1.head(10)\n",
    "else:\n",
    "\t# List available files in the directory to help find the correct file\n",
    "\tdata_dir = os.path.join(parent_dir, 'data', 'factal')\n",
    "\tif os.path.exists(data_dir):\n",
    "\t\tprint(f\"Available files in {data_dir}:\")\n",
    "\t\tfor file in os.listdir(data_dir):\n",
    "\t\t\tprint(f\"- {file}\")\n",
    "\telse:\n",
    "\t\tprint(f\"Directory not found: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646aee4",
   "metadata": {},
   "source": [
    "# 2. Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9bfa627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph that will be used for creating security reports for different countries.\n",
      "\n",
      "Extract the entities (nodes) and specify their type, location, affiliation, severity, etc. from the Input text.nThe text describes a security incident. The text contains names of the following entitites: Country, State, Town, Location of the incident, Actors.\n",
      "The text also contains additional data like Actors affiliations, severity of the incident, number of fatalities, type of event - store these details as node properties.\n",
      "Also extract the relationships between these nodes. The relationship direction goes from the start node to the end node.\n",
      "\n",
      "Return result as JSON using the following format:\n",
      "{{\"nodes\": [ {{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {{\"name\": \"name of entity\", \"type\": \"type of node\", \"location\": \"location, town, state, country that the node is associated with\" }} }}],\n",
      "\"relationships\": [{{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"details\": \"Description of the relationship\"}} }}] }}\n",
      "\n",
      "- Use only the information from the Input text. Do not create edges between nodes and chunks when the relationship is not clear enough.\n",
      "\n",
      "Use only the following nodes and relationships (if provided):\n",
      "{schema}\n",
      "\n",
      "Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
      "Do not return any additional information other than the JSON in it.\n",
      "\n",
      "Examples:\n",
      "{examples}\n",
      "\n",
      "Input text:\n",
      "{text}\n"
     ]
    }
   ],
   "source": [
    "prompt_template=config['prompt_template_config']['template'] if config['prompt_template_config'].get('use_default') == False else None\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e872a9",
   "metadata": {},
   "source": [
    "## 2.2. With a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c023659",
   "metadata": {},
   "source": [
    "### A. Using the `SpaCySemanticMatchResolver`\n",
    "\n",
    "More useful information about the resolvers can be found in the [user guide](https://neo4j.com/docs/neo4j-graphrag-python/current/user_guide_kg_builder.html#entity-resolver). Below, we use different resolvers (from the most aggressive - spaCy to the most conservative - exact matching) to get a broad overview of the performance results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2a91f2",
   "metadata": {},
   "source": [
    "#### With Factal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bff7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the first dataframe...\n",
      "Processing row 1 of 10\n",
      "Result: run_id='2819be1a-f71b-4e44-a3bc-679508a05e3b' result={'resolver': {'number_of_nodes_to_resolve': 43, 'number_of_created_nodes': 2}}\n",
      "Elapsed time: 30.22 seconds\n",
      "Estimated time remaining: 271.98 seconds\n",
      "\n",
      "Processing row 2 of 10\n",
      "Result: run_id='54e10403-ff25-4220-9c08-44d047787ea6' result={'resolver': {'number_of_nodes_to_resolve': 46, 'number_of_created_nodes': 2}}\n",
      "Elapsed time: 50.27 seconds\n",
      "Estimated time remaining: 201.08 seconds\n",
      "\n",
      "Processing row 3 of 10\n",
      "Result: run_id='90ad9e47-e250-4de7-9bd9-81b1972fec60' result={'resolver': {'number_of_nodes_to_resolve': 51, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 69.79 seconds\n",
      "Estimated time remaining: 162.84 seconds\n",
      "\n",
      "Processing row 4 of 10\n",
      "Result: run_id='1b55f714-0f15-4c41-bb72-16cc68551050' result={'resolver': {'number_of_nodes_to_resolve': 56, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 111.48 seconds\n",
      "Estimated time remaining: 167.23 seconds\n",
      "\n",
      "Processing row 5 of 10\n",
      "Result: run_id='971009de-ee8d-4670-86c4-12e5ac77ebe6' result={'resolver': {'number_of_nodes_to_resolve': 66, 'number_of_created_nodes': 3}}\n",
      "Elapsed time: 139.99 seconds\n",
      "Estimated time remaining: 139.99 seconds\n",
      "\n",
      "Processing row 6 of 10\n",
      "Result: run_id='d2024699-4fea-4a18-a7d5-f2bc44051600' result={'resolver': {'number_of_nodes_to_resolve': 71, 'number_of_created_nodes': 4}}\n",
      "Elapsed time: 166.78 seconds\n",
      "Estimated time remaining: 111.19 seconds\n",
      "\n",
      "Processing row 7 of 10\n",
      "Result: run_id='e043d167-2d48-408e-aac5-bd753564370a' result={'resolver': {'number_of_nodes_to_resolve': 72, 'number_of_created_nodes': 2}}\n",
      "Elapsed time: 187.65 seconds\n",
      "Estimated time remaining: 80.42 seconds\n",
      "\n",
      "Processing row 8 of 10\n",
      "Result: run_id='8bd49cfa-bb9f-42f7-b64a-d695eefb2ce9' result={'resolver': {'number_of_nodes_to_resolve': 75, 'number_of_created_nodes': 3}}\n",
      "Elapsed time: 211.38 seconds\n",
      "Estimated time remaining: 52.84 seconds\n",
      "\n",
      "Processing row 9 of 10\n",
      "Result: run_id='4181c6bd-c74d-4467-b4d8-5e785e712479' result={'resolver': {'number_of_nodes_to_resolve': 80, 'number_of_created_nodes': 5}}\n",
      "Elapsed time: 237.47 seconds\n",
      "Estimated time remaining: 26.39 seconds\n",
      "\n",
      "Processing row 10 of 10\n",
      "Result: run_id='63cae6f7-7210-4fc8-8e84-4cd942923c34' result={'resolver': {'number_of_nodes_to_resolve': 82, 'number_of_created_nodes': 3}}\n",
      "Elapsed time: 268.90 seconds\n",
      "Estimated time remaining: 0.00 seconds\n",
      "\n",
      "Processed 10 documents\n"
     ]
    }
   ],
   "source": [
    "# Example usage code\n",
    "async def main():\n",
    "\n",
    "    # Find path to config_files folder\n",
    "    config_files_path = os.path.join(os.path.dirname(os.getcwd()), 'config_files')\n",
    "\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv(os.path.join(config_files_path, '.env'), override=True)\n",
    "    \n",
    "    with open(os.path.join(config_files_path, 'kg_building_config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Neo4j connection\n",
    "    neo4j_uri = os.getenv('NEO4J_URI')\n",
    "    neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "    neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "    \n",
    "    # Check if gemini_api_key is set\n",
    "    if gemini_api_key:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Gemini API key is not set. Please provide a valid API key.\")\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = GeminiLLM(\n",
    "        model_name=config['llm_config']['model_name'],\n",
    "        google_api_key=gemini_api_key,\n",
    "        model_params=config['llm_config']['model_params']\n",
    "    )\n",
    "    \n",
    "    # Initialize embedder\n",
    "    embedder = SentenceTransformerEmbeddings(model=config['embedder_config']['model_name'])\n",
    "    \n",
    "    # Configure text splitter\n",
    "    text_splitter_config = config['text_splitter_config'] \n",
    "    \n",
    "    # Create the pipeline - use with statement to ensure proper resource management\n",
    "    # and to ensure the driver is closed after use\n",
    "    all_results = []\n",
    "    with neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password)) as driver:\n",
    "        \n",
    "        # Initialize entity resolver\n",
    "        resolver = SpaCySemanticMatchResolver(  # Merge nodes with same label and similar textual properties\n",
    "            driver,\n",
    "            filter_query=None,  # \"WHERE (entity)-[:FROM_CHUNK]->(:Chunk)-[:FROM_DOCUMENT]->(doc:Document {id = 'docId'}\",  # Used to reduce the resolution scope to a specific document\n",
    "            resolve_properties=[\"name\"],  # Properties to use for resolution (default is \"name\")\n",
    "            similarity_threshold=0.8,  # The similarity threshold above which nodes are merged (default is 0.8). Higher threshold will result in less false positives, but may miss some matches. \n",
    "            spacy_model=\"en_core_web_lg\"  # spaCy model to use for resolution (default is \"en_core_web_lg\")\n",
    "        )\n",
    "\n",
    "        # Initialize the custom KG pipeline\n",
    "        kg_pipeline = CustomKGPipeline(\n",
    "            llm=llm,\n",
    "            driver=driver,\n",
    "            embedder=embedder,\n",
    "            schema_config=config['schema_config'],\n",
    "            prompt_template=config['prompt_template_config']['template'] if config['prompt_template_config'].get('use_default') == False else None,\n",
    "            text_splitter_config=text_splitter_config,\n",
    "            resolver=resolver,\n",
    "            examples_config=None,  # Use None if no examples are provided\n",
    "            on_error='RAISE',\n",
    "            batch_size=1000,\n",
    "            max_concurrency=5\n",
    "        )\n",
    "    \n",
    "        \n",
    "        # Process the First dataframe\n",
    "        print(\"Processing the first dataframe...\")\n",
    "        results_df1 = await build_kg_from_df(\n",
    "            kg_pipeline=kg_pipeline,\n",
    "            df=df1,\n",
    "            document_base_field='item_id',\n",
    "            text_column='text',\n",
    "            document_id_column='item_id'  # Use default document ID generation\n",
    "        )\n",
    "        all_results.extend(results_df1)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Asyncio event loop to run the main function in a Jupyter notebook\n",
    "all_results = await main()\n",
    "print(f\"Processed {len(all_results)} documents\")\n",
    "\n",
    "# # Asyncio event loop to run the main function in a script\n",
    "# if __name__ == \"__main__\":\n",
    "#     results = asyncio.run(main())\n",
    "#     print(f\"Processed {len(results)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67cb35f",
   "metadata": {},
   "source": [
    "# Entity Resolution Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7527a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOC is available.\n",
      "Found 48 entities to process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f943dfa466a42c4ad137310e41c7486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing similarity scores:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 similar entity pairs.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv(\"NEO4J_URI\"),\n",
    "    auth=(\"neo4j\", os.getenv(\"NEO4J_PASSWORD\"))\n",
    ")\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "def get_embedding(text):\n",
    "    return model.encode(text).tolist()\n",
    "\n",
    "# List of relevant node labels for deduplication\n",
    "ENTITY_LABELS = [\"Event\", \"Actor\", \"Country\", \"ADM1\", \"Location\"]\n",
    "\n",
    "def get_all_entities():\n",
    "    query_template = \"\"\"\n",
    "    MATCH (n:{label})\n",
    "    RETURN elementId(n) AS id, labels(n) AS labels, n.name AS name, properties(n) AS properties\n",
    "    \"\"\"\n",
    "    all_entities = []\n",
    "    with driver.session() as session:\n",
    "        for label in ENTITY_LABELS:\n",
    "            result = session.run(query_template.format(label=label)).data()\n",
    "            all_entities.extend(result)\n",
    "    return all_entities\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if vec1 is None or vec2 is None or len(vec1) == 0 or len(vec2) == 0:\n",
    "        return 0  # If either vector is None or empty, return 0 similarity\n",
    "    dot = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0\n",
    "\n",
    "def find_similar_entities(threshold=0.7):\n",
    "    entities = get_all_entities()\n",
    "    print(f\"Found {len(entities)} entities to process\")\n",
    "    \n",
    "    # Compute embeddings\n",
    "    for entity in entities:\n",
    "        # Filter out \"__KGBuilder__\" from labels\n",
    "        filtered_labels = [l for l in entity['labels'] if l != \"__KGBuilder__\" and l != \"__Entity__\"]\n",
    "        if filtered_labels:  # If there are any labels left\n",
    "            entity['primary_label'] = filtered_labels[0]\n",
    "        else:\n",
    "            entity['primary_label'] = entity['labels'][0]  # Fallback if only __KGBuilder__ is present\n",
    "            \n",
    "        # Start with entity label/type and name\n",
    "        text = f\"Type: {entity['primary_label']}\\nName: {entity['name']}\\n\"\n",
    "        \n",
    "        # Rest of embedding code remains the same\n",
    "        for key, value in entity['properties'].items():\n",
    "            if key != 'embedding' and value is not None:\n",
    "                if isinstance(value, (list, dict)):\n",
    "                    formatted_value = str(value)\n",
    "                else:\n",
    "                    formatted_value = value\n",
    "                text += f\"{key}: {formatted_value}\\n\"\n",
    "        \n",
    "        entity['embedding'] = get_embedding(text)\n",
    "     \n",
    "    # Find similar pairs with the new label comparison\n",
    "    similar_pairs = []\n",
    "    total_comparisons = sum(range(len(entities)))\n",
    "    for i, e1 in enumerate(entities):\n",
    "        for j, e2 in enumerate(entities[i + 1:], i + 1):\n",
    "            # Only compare if they have the same primary label (excluding __KGBuilder__)\n",
    "            if e1['primary_label'] != e2['primary_label'] or e1['primary_label'] == \"__KGBuilder__\":\n",
    "                continue\n",
    "            \n",
    "            sim = cosine_similarity(e1['embedding'], e2['embedding'])\n",
    "            if sim > threshold:\n",
    "                similar_pairs.append({\n",
    "                    \"id1\": e1['id'],\n",
    "                    \"id2\": e2['id'],\n",
    "                    \"name1\": e1['name'],\n",
    "                    \"name2\": e2['name'],\n",
    "                    \"type1\": e1['primary_label'],\n",
    "                    \"type2\": e2['primary_label'],\n",
    "                    \"similarity\": sim\n",
    "                })\n",
    "    \n",
    "    # Create SAME_AS relationships\n",
    "    query = \"\"\"\n",
    "    MATCH (a), (b)\n",
    "    WHERE elementId(a) = $id1 AND elementId(b) = $id2\n",
    "    MERGE (a)-[:SAME_AS {similarity: $similarity}]->(b)\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        for pair in tqdm.tqdm(similar_pairs, desc=\"Computing similarity scores\"):\n",
    "            session.run(query, pair)\n",
    "    \n",
    "    return similar_pairs\n",
    "\n",
    "def merge_similar_nodes():\n",
    "    merge_query = \"\"\"\n",
    "    // Process one pair of nodes at a time to avoid conflicts\n",
    "    MATCH (n1)-[r:SAME_AS]->(n2)\n",
    "    WHERE n1 IS NOT NULL AND n2 IS NOT NULL\n",
    "    \n",
    "    // Copy properties from n2 to n1 if they don't exist in n1\n",
    "    WITH n1, n2, [key IN keys(n2) WHERE NOT key IN keys(n1)] AS newKeys\n",
    "    FOREACH (key IN newKeys | SET n1[key] = n2[key])\n",
    "    \n",
    "    // Get all outgoing relationships from n2 (except SAME_AS)\n",
    "    WITH n1, n2\n",
    "    OPTIONAL MATCH (n2)-[outRel]->(target)\n",
    "    WHERE target IS NOT NULL AND type(outRel) <> 'SAME_AS'\n",
    "    \n",
    "    // Create equivalent relationships from n1 if they don't already exist\n",
    "    WITH n1, n2, outRel, target, type(outRel) AS relType\n",
    "    WHERE NOT EXISTS((n1)-[:`${relType}`]->(target))\n",
    "    \n",
    "    // Create new relationship with the same properties\n",
    "    FOREACH (_ IN CASE WHEN outRel IS NOT NULL THEN [1] ELSE [] END |\n",
    "        CREATE (n1)-[newRel:`${relType}`]->(target)\n",
    "        SET newRel = properties(outRel)\n",
    "    )\n",
    "    \n",
    "    // Return the node pair for the next phase\n",
    "    WITH DISTINCT n1, n2\n",
    "    \n",
    "    // Handle incoming relationships\n",
    "    OPTIONAL MATCH (source)-[inRel]->(n2)\n",
    "    WHERE source IS NOT NULL AND source <> n1 AND type(inRel) <> 'SAME_AS'\n",
    "    \n",
    "    // Create equivalent relationships to n1 if they don't already exist\n",
    "    WITH n1, n2, inRel, source, type(inRel) AS relType\n",
    "    WHERE NOT EXISTS((source)-[:`${relType}`]->(n1))\n",
    "    \n",
    "    // Create new relationship with the same properties\n",
    "    FOREACH (_ IN CASE WHEN inRel IS NOT NULL THEN [1] ELSE [] END |\n",
    "        CREATE (source)-[newRel:`${relType}`]->(n1)\n",
    "        SET newRel = properties(inRel)\n",
    "    )\n",
    "    \n",
    "    // Return distinct pairs for deletion phase\n",
    "    WITH DISTINCT n1, n2\n",
    "    \n",
    "    // Delete the second node and all its relationships\n",
    "    DETACH DELETE n2\n",
    "    \n",
    "    RETURN count(n2) AS mergedCount\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(merge_query)\n",
    "            record = result.single()\n",
    "            return record[\"mergedCount\"] if record else 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error during node merging: {e}\")\n",
    "        return 0\n",
    "\n",
    "def check_apoc():\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            session.run(\"CALL apoc.help('create')\")\n",
    "            print(\"APOC is available.\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"APOC not available: {e}\")\n",
    "        return False\n",
    "\n",
    "# === MAIN EXECUTION ===\n",
    "check_apoc()\n",
    "pairs = find_similar_entities()\n",
    "pairs = sorted(pairs, key=lambda x: x[\"similarity\"], reverse=True)\n",
    "print(f\"Found {len(pairs)} similar entity pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be4205df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:227', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:282', 'name1': 'Kutum', 'name2': 'Kubum', 'type1': 'Location', 'type2': 'Location', 'similarity': np.float64(0.9554210593764909)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:19', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:368', 'name1': 'military', 'name2': 'army', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9545791105950588)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:4', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:53', 'name1': 'Sudan doctors union', 'name2': 'Sudan Doctors Network', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9404681965196532)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:47', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:105', 'name1': 'Cholera outbreak', 'name2': 'cholera-related deaths and infections', 'type1': 'Event', 'type2': 'Event', 'similarity': np.float64(0.9379905887483682)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:22', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:71', 'name1': 'Sudanese government', 'name2': 'Sudan health authorities', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9242922749244303)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:0', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:47', 'name1': '727 cholera cases', 'name2': 'Cholera outbreak', 'type1': 'Event', 'type2': 'Event', 'similarity': np.float64(0.9226276889101158)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:0', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:105', 'name1': '727 cholera cases', 'name2': 'cholera-related deaths and infections', 'type1': 'Event', 'type2': 'Event', 'similarity': np.float64(0.9214347261225326)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:189', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:355', 'name1': 'Bahri', 'name2': 'Bahr Al Arab', 'type1': 'Location', 'type2': 'Location', 'similarity': np.float64(0.9054276767911795)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:4', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:71', 'name1': 'Sudan doctors union', 'name2': 'Sudan health authorities', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.902051708901004)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:43', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:147', 'name1': 'WHO', 'name2': 'WFP', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9019962818021556)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:605', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:639', 'name1': 'Formation of New Government', 'name2': 'Government Dissolution', 'type1': 'Event', 'type2': 'Event', 'similarity': np.float64(0.9018204702396523)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:6', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:100', 'name1': 'an adult', 'name2': '70 people', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9009297165393891)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:151', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:195', 'name1': 'Kassala', 'name2': 'Karrari', 'type1': 'Location', 'type2': 'Location', 'similarity': np.float64(0.9003306986191377)}]\n"
     ]
    }
   ],
   "source": [
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_similar_nodes()\n",
    "print(f\"Merged {merged} nodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c57305",
   "metadata": {},
   "source": [
    "### Node similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_similarity_query = \"\"\"\n",
    "CALL gds.nodeSimilarity.stream('amazonGraph')\n",
    "YIELD node1, node2, similarity as node_similarity\n",
    "WHERE 'Company' IN labels(gds.util.asNode(node1)) AND 'Company' IN labels(gds.util.asNode(node2))\n",
    "AND node_similarity < 1\n",
    "RETURN gds.util.asNode(node1).name AS Company1, gds.util.asNode(node2).name AS Company2, node_similarity\n",
    "ORDER BY node_similarity DESCENDING, Company1, Company2\n",
    "\"\"\"\n",
    "\n",
    "def results_to_df(query: str) -> pd.DataFrame:\n",
    "    results = gds.execute_query(query)[0]\n",
    "    df = pd.DataFrame(results, columns=results[0].keys())\n",
    "    return df\n",
    "\n",
    "df_node_similarity = results_to_df(node_similarity_query)\n",
    "print(df_node_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb28fec",
   "metadata": {},
   "source": [
    "### Create SAME_AS relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e661965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_same_as_relationship(df, column_name):\n",
    "    # Iterate over the DataFrame rows\n",
    "    for _, row in df.iterrows():\n",
    "        node1 = row[column_name + '1']\n",
    "        node2 = row[column_name + '2']\n",
    "\n",
    "        # Run Cypher query to create 'SAME_AS' relationship\n",
    "        score = row[\"combined_score\"]\n",
    "        if score > 0.20:\n",
    "            query = f\"MATCH (n1), (n2) WHERE n1.name = '{node1}' AND n2.name = '{node2}' CREATE (n1)-[:SAME_AS]->(n2)\"\n",
    "            gds.execute_query(query)\n",
    "\n",
    "create_same_as_relationship(selected_df, \"Company\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52dbed9",
   "metadata": {},
   "source": [
    "### Merge nodes with SAME_AS relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_query = \"\"\"\n",
    "MATCH (n1)-[r:SAME_AS]->(n2)\n",
    "WITH n1, n2, collect(r) as relsToDel\n",
    "\n",
    "FOREACH (rel IN relsToDel | DELETE rel)\n",
    "WITH collect(DISTINCT n1) + collect(DISTINCT n2) AS nodesToMerge\n",
    "\n",
    "UNWIND nodesToMerge AS node\n",
    "\n",
    "WITH collect(DISTINCT node) AS uniqueNodesToMerge\n",
    "CALL apoc.refactor.mergeNodes(uniqueNodesToMerge, {mergeRels:true}) YIELD node\n",
    "RETURN node\n",
    "\"\"\"\n",
    "\n",
    "gds.execute_query(merge_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
