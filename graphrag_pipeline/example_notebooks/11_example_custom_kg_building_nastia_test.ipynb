{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae0c9b",
   "metadata": {},
   "source": [
    "# Custom Knowledge Graph Building and Entity Resolution Pipeline\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Building a knowledge graph from ACLED data using the CustomKGPipeline\n",
    "2. Performing entity resolution using embedding-based similarity matching\n",
    "3. Merging similar entities to create a cleaner knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a8341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory (graphrag_pipeline) to the Python path (needed for importing\n",
    "# modules in parent directory)\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Utilities\n",
    "import asyncio\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "import polars as pl\n",
    "from library.kg_builder import CustomKGPipeline, build_kg_from_df\n",
    "from library.kg_builder.utilities import GeminiLLM\n",
    "from neo4j_graphrag.experimental.components.resolver import (\n",
    "    SpaCySemanticMatchResolver, FuzzyMatchResolver, SinglePropertyExactMatchResolver\n",
    ")\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "# Neo4j and Neo4j GraphRAG imports\n",
    "import neo4j\n",
    "from neo4j_graphrag.embeddings import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b114e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='models/embedding-gecko-001' display_name='Embedding Gecko' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1024 output_token_limit=1 supported_actions=['embedText', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.0-pro-vision-latest' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-pro-vision' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-latest' display_name='Gemini 1.5 Pro Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-002' display_name='Gemini 1.5 Pro 002' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro' display_name='Gemini 1.5 Pro' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-latest' display_name='Gemini 1.5 Flash Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash' display_name='Gemini 1.5 Flash' description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-002' display_name='Gemini 1.5 Flash 002' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b' display_name='Gemini 1.5 Flash-8B' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-001' display_name='Gemini 1.5 Flash-8B 001' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-latest' display_name='Gemini 1.5 Flash-8B Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-03-25' display_name='Gemini 2.5 Pro Preview 03-25' description='Gemini 2.5 Pro Preview 03-25' version='2.5-preview-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-04-17' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-05-20' display_name='Gemini 2.5 Flash Preview 05-20' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-05-20' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash' display_name='Gemini 2.5 Flash' description='Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-04-17-thinking' display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-lite-preview-06-17' display_name='Gemini 2.5 Flash-Lite Preview 06-17' description='Preview release (June 11th, 2025) of Gemini 2.5 Flash-Lite' version='2.5-preview-06-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-05-06' display_name='Gemini 2.5 Pro Preview 05-06' description='Preview release (May 6th, 2025) of Gemini 2.5 Pro' version='2.5-preview-05-06' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-06-05' display_name='Gemini 2.5 Pro Preview' description='Preview release (June 5th, 2025) of Gemini 2.5 Pro' version='2.5-preview-06-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro' display_name='Gemini 2.5 Pro' description='Stable release (June 17th, 2025) of Gemini 2.5 Pro' version='2.5' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-exp' display_name='Gemini 2.0 Flash Experimental' description='Gemini 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash' display_name='Gemini 2.0 Flash' description='Gemini 2.0 Flash' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-001' display_name='Gemini 2.0 Flash 001' description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-001' display_name='Gemini 2.0 Flash-Lite 001' description='Stable version of Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite' display_name='Gemini 2.0 Flash-Lite' description='Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-preview-02-05' display_name='Gemini 2.0 Flash-Lite Preview 02-05' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-preview' display_name='Gemini 2.0 Flash-Lite Preview' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-pro-exp' display_name='Gemini 2.0 Pro Experimental' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-pro-exp-02-05' display_name='Gemini 2.0 Pro Experimental 02-05' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-exp-1206' display_name='Gemini Experimental 1206' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp-01-21' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp-1219' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-tts' display_name='Gemini 2.5 Flash Preview TTS' description='Gemini 2.5 Flash Preview TTS' version='gemini-2.5-flash-exp-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=16384 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-tts' display_name='Gemini 2.5 Pro Preview TTS' description='Gemini 2.5 Pro Preview TTS' version='gemini-2.5-pro-preview-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=16384 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/learnlm-2.0-flash-experimental' display_name='LearnLM 2.0 Flash Experimental' description='LearnLM 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=32768 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-1b-it' display_name='Gemma 3 1B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-4b-it' display_name='Gemma 3 4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-12b-it' display_name='Gemma 3 12B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-27b-it' display_name='Gemma 3 27B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3n-e4b-it' display_name='Gemma 3n E4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3n-e2b-it' display_name='Gemma 3n E2B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/embedding-001' display_name='Embedding 001' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/text-embedding-004' display_name='Text Embedding 004' description='Obtain a distributed representation of a text.' version='004' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-embedding-exp-03-07' display_name='Gemini Embedding Experimental 03-07' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-embedding-exp' display_name='Gemini Embedding Experimental' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/aqa' display_name='Model that performs Attributed Question Answering.' description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=7168 output_token_limit=1024 supported_actions=['generateAnswer'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/imagen-3.0-generate-002' display_name='Imagen 3.0 002 model' description='Vertex served Imagen 3.0 002 model' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/imagen-4.0-generate-preview-06-06' display_name='Imagen 4 (Preview)' description='Vertex served Imagen 4.0 model' version='01' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/imagen-4.0-ultra-generate-preview-06-06' display_name='Imagen 4 Ultra (Preview)' description='Vertex served Imagen 4.0 ultra model' version='01' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/veo-2.0-generate-001' display_name='Veo 2' description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-native-audio-dialog' display_name='Gemini 2.5 Flash Preview Native Audio Dialog' description='Gemini 2.5 Flash Preview Native Audio Dialog' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-exp-native-audio-thinking-dialog' display_name='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' description='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' version='gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-live-001' display_name='Gemini 2.0 Flash 001' description='Gemini 2.0 Flash 001' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['bidiGenerateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-live-2.5-flash-preview' display_name='Gemini Live 2.5 Flash Preview' description='Gemini Live 2.5 Flash Preview' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['bidiGenerateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable is not set.\")\n",
    "\n",
    "print(\"✓ Gemini API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad2805",
   "metadata": {},
   "source": [
    "## Setup Requirements\n",
    "\n",
    "Ensure the SpaCy model for entity resolution is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43270dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'en_core_web_lg' is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "import spacy\n",
    "\n",
    "\n",
    "def ensure_spacy_model(model_name):\n",
    "    \"\"\"Ensure SpaCy model is installed, install if not present.\"\"\"\n",
    "    if importlib.util.find_spec(model_name) is None:\n",
    "        print(f\"Installing SpaCy model: {model_name}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", model_name])\n",
    "    else:\n",
    "        print(f\"✓ SpaCy model '{model_name}' is available\")\n",
    "\n",
    "# Install required model for entity resolution\n",
    "ensure_spacy_model(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a0a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_default': False,\n",
       " 'template': 'You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph that will be used for creating security reports for different countries.\\n\\nExtract the entities (nodes) and specify their type from the following Input text.\\nAlso extract the relationships between these nodes. The relationship direction goes from the start node to the end node.\\n\\nReturn result as JSON using the following format:\\n{\"nodes\": [{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {\"name\": \"name of entity\" }}],\\n\"relationships\": [{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {\"details\": \"Description of the relationship\"}}]}\\n\\n- Use only the information from the Input text. Do not add any additional information.\\n- Make sure to create as many nodes and relationships as needed to offer rich context.\\n- Use only the provided schema.\\n\\nInput text:\\n{text}'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open(os.path.join(config_files_path, 'kg_building_config2.json'), 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(\"✓ Configuration loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39afcd",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Preparation\n",
    "\n",
    "The data is loaded here as a reference, but it is loaded again inside the pipeline below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a4e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>Published date</th><th>Severity</th><th>Text</th><th>Translated text</th><th>Original language</th><th>Source URL</th><th>Status</th><th>Country</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;1&quot;</td><td>&quot;2025-06-03 15:28:28.271179+00:…</td><td>3</td><td>&quot;WFP and UNICEF now say five me…</td><td>null</td><td>null</td><td>&quot;https://www.unicef.org/press-r…</td><td>&quot;published&quot;</td><td>&quot;Sudan&quot;</td></tr><tr><td>&quot;2&quot;</td><td>&quot;2025-06-03 10:10:04.994458+00:…</td><td>3</td><td>&quot;&quot;Multiple casualties&quot; after WF…</td><td>null</td><td>null</td><td>&quot;https://www.reuters.com/world/…</td><td>&quot;published&quot;</td><td>&quot;Sudan&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "┌─────┬──────────────┬──────────┬──────────────┬───┬──────────┬──────────────┬───────────┬─────────┐\n",
       "│ id  ┆ Published    ┆ Severity ┆ Text         ┆ … ┆ Original ┆ Source URL   ┆ Status    ┆ Country │\n",
       "│ --- ┆ date         ┆ ---      ┆ ---          ┆   ┆ language ┆ ---          ┆ ---       ┆ ---     │\n",
       "│ str ┆ ---          ┆ i64      ┆ str          ┆   ┆ ---      ┆ str          ┆ str       ┆ str     │\n",
       "│     ┆ str          ┆          ┆              ┆   ┆ str      ┆              ┆           ┆         │\n",
       "╞═════╪══════════════╪══════════╪══════════════╪═══╪══════════╪══════════════╪═══════════╪═════════╡\n",
       "│ 1   ┆ 2025-06-03   ┆ 3        ┆ WFP and      ┆ … ┆ null     ┆ https://www. ┆ published ┆ Sudan   │\n",
       "│     ┆ 15:28:28.271 ┆          ┆ UNICEF now   ┆   ┆          ┆ unicef.org/p ┆           ┆         │\n",
       "│     ┆ 179+00:…     ┆          ┆ say five me… ┆   ┆          ┆ ress-r…      ┆           ┆         │\n",
       "│ 2   ┆ 2025-06-03   ┆ 3        ┆ \"Multiple    ┆ … ┆ null     ┆ https://www. ┆ published ┆ Sudan   │\n",
       "│     ┆ 10:10:04.994 ┆          ┆ casualties\"  ┆   ┆          ┆ reuters.com/ ┆           ┆         │\n",
       "│     ┆ 458+00:…     ┆          ┆ after WF…    ┆   ┆          ┆ world/…      ┆           ┆         │\n",
       "└─────┴──────────────┴──────────┴──────────────┴───┴──────────┴──────────────┴───────────┴─────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global df1\n",
    "\n",
    "df1 = pl.read_csv(os.path.join('sample_data', 'factal_single_topic_report-2025-05-01-2025-06-05.csv'))\n",
    "df1 = df1.rename({\"Associated topics\": \"Country\"})\n",
    "df1 = df1.rename({\"Published text\": \"Text\"})\n",
    "\n",
    "df1=df1.head(10)\n",
    "\n",
    "# Create an index for each row\n",
    "df1 = df1.with_row_index(name=\"id\", offset=1)\n",
    "# Convert the \"id\" to a string to ensure it is treated as a document ID\n",
    "df1 = df1.with_columns(pl.col('id').cast(pl.String))\n",
    "    \n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c640450",
   "metadata": {},
   "source": [
    "### Load Admin1 locations from HDX database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7cbcb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matia\\AppData\\Local\\Temp\\ipykernel_36456\\4137613185.py:33: DeprecationWarning: the `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "(Deprecated in version 1.0.0)\n",
      "  pl.col(\"Parent P-Code\").replace(sudan_states_mapping, default=pl.col(\"Parent P-Code\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>Text</th><th>Admin1</th><th>Country</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;1&quot;</td><td>&quot;Khartoum&quot;</td><td>&quot;Khartoum&quot;</td><td>&quot;Sudan&quot;</td></tr><tr><td>&quot;2&quot;</td><td>&quot;North Darfur&quot;</td><td>&quot;North Darfur&quot;</td><td>&quot;Sudan&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌─────┬──────────────┬──────────────┬─────────┐\n",
       "│ id  ┆ Text         ┆ Admin1       ┆ Country │\n",
       "│ --- ┆ ---          ┆ ---          ┆ ---     │\n",
       "│ str ┆ str          ┆ str          ┆ str     │\n",
       "╞═════╪══════════════╪══════════════╪═════════╡\n",
       "│ 1   ┆ Khartoum     ┆ Khartoum     ┆ Sudan   │\n",
       "│ 2   ┆ North Darfur ┆ North Darfur ┆ Sudan   │\n",
       "└─────┴──────────────┴──────────────┴─────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global df2\n",
    "admin1 = pl.read_csv(r\"C:\\Users\\matia\\Downloads\\global_pcodes_adm_1_2.csv\")\n",
    "df2 = admin1.filter(pl.col('Location') == 'SDN').clone()\n",
    "df2 = df2.with_columns(pl.lit('Sudan').alias('Country'))\n",
    "df2 = df2.rename({\"Name\": \"Text\"})\n",
    "\n",
    "sudan_states_mapping = {\n",
    "    \"SD01\": \"Khartoum\",\n",
    "    \"SD02\": \"North Darfur\",\n",
    "    \"SD03\": \"South Darfur\",\n",
    "    \"SD04\": \"West Darfur\",\n",
    "    \"SD05\": \"East Darfur\",\n",
    "    \"SD06\": \"Central Darfur\",\n",
    "    \"SD07\": \"South Kordofan\",\n",
    "    \"SD08\": \"Blue Nile\",\n",
    "    \"SD09\": \"White Nile\",\n",
    "    \"SD10\": \"Red Sea\",\n",
    "    \"SD11\": \"Kassala\",\n",
    "    \"SD12\": \"Gedaref\",\n",
    "    \"SD13\": \"North Kordofan\",\n",
    "    \"SD14\": \"Sennar\",\n",
    "    \"SD15\": \"Aj Jazirah\",\n",
    "    \"SD16\": \"River Nile\",\n",
    "    \"SD17\": \"Northern\",\n",
    "    \"SD18\": \"West Kordofan\",\n",
    "    \"SD19\": \"Abyei PCA\"\n",
    "}\n",
    "\n",
    "df2 = df2.with_columns(\n",
    "    pl.when(pl.col(\"Parent P-Code\") == \"SDN\")\n",
    "    .then(pl.col(\"Text\"))\n",
    "    .otherwise(\n",
    "        pl.col(\"Parent P-Code\").replace(sudan_states_mapping, default=pl.col(\"Parent P-Code\"))\n",
    "    )\n",
    "    .alias(\"Admin1\")\n",
    ")\n",
    "\n",
    "df2 = df2.select(['Text', 'Admin1', 'Country'])\n",
    "df2 = df2.head(15)\n",
    "\n",
    "# Create an index for each row if df2 doesn't already have an 'id' column\n",
    "if 'id' not in df2.columns:\n",
    "    df2 = df2.with_row_index(name=\"id\", offset=1)\n",
    "    # Convert the \"id\" to a string to ensure it is treated as a document ID\n",
    "    df2 = df2.with_columns(pl.col('id').cast(pl.String))\n",
    "        \n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdf4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ACLED data\n",
    "file_path = os.path.join(parent_dir, 'data', 'acled', 'Acled_Sudan_2025-05-01_2025-05-31.parquet')\n",
    "\n",
    "try:\n",
    "    df1 = pl.read_parquet(file_path)\n",
    "    df1 = df1.head(10)  # Use first 10 rows for testing\n",
    "    print(f\"✓ Loaded {len(df1)} rows from ACLED data\")\n",
    "    print(f\"Columns: {df1.columns}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ File not found: {file_path}\")\n",
    "    # List available files\n",
    "    data_dir = os.path.dirname(file_path)\n",
    "    if os.path.exists(data_dir):\n",
    "        print(f\"Available files in {data_dir}:\")\n",
    "        for file in os.listdir(data_dir):\n",
    "            print(f\"  - {file}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646aee4",
   "metadata": {},
   "source": [
    "# 2. Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9bfa627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph that will be used for creating security reports for different countries.\n",
      "\n",
      "Extract the entities (nodes) and specify their type from the following Input text.\n",
      "Also extract the relationships between these nodes. The relationship direction goes from the start node to the end node.\n",
      "\n",
      "Return result as JSON using the following format:\n",
      "{\"nodes\": [{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {\"name\": \"name of entity\" }}],\n",
      "\"relationships\": [{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {\"details\": \"Description of the relationship\"}}]}\n",
      "\n",
      "- Use only the information from the Input text. Do not add any additional information.\n",
      "- Make sure to create as many nodes and relationships as needed to offer rich context.\n",
      "- Use only the provided schema.\n",
      "\n",
      "Input text:\n",
      "{text}\n"
     ]
    }
   ],
   "source": [
    "prompt_template=config['prompt_template_config']['template'] if config['prompt_template_config'].get('use_default') == False else None\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e872a9",
   "metadata": {},
   "source": [
    "## 2.2. With a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c023659",
   "metadata": {},
   "source": [
    "## Pipeline Configuration\n",
    "\n",
    "More useful information about the resolvers can be found in the [user guide](https://neo4j.com/docs/neo4j-graphrag-python/current/user_guide_kg_builder.html#entity-resolver). Below, we use different resolvers (from the most aggressive - spaCy to the most conservative - exact matching) to get a broad overview of the performance results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2a91f2",
   "metadata": {},
   "source": [
    "#### With Factal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bff7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the first dataframe...\n",
      "Processing row 1 of 10\n",
      "Result: run_id='ac672be4-5835-474e-bd25-d2668f510f4b' result={'resolver': {'number_of_nodes_to_resolve': 5, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 6.21 seconds\n",
      "Estimated time remaining: 55.86 seconds\n",
      "\n",
      "Processing row 2 of 10\n",
      "Result: run_id='843a3db5-4e71-4a81-b54c-3fdf072a73c7' result={'resolver': {'number_of_nodes_to_resolve': 13, 'number_of_created_nodes': 5}}\n",
      "Elapsed time: 20.29 seconds\n",
      "Estimated time remaining: 81.17 seconds\n",
      "\n",
      "Processing row 3 of 10\n",
      "Result: run_id='86a56c3d-1e2a-45b7-aac0-3648abf87989' result={'resolver': {'number_of_nodes_to_resolve': 14, 'number_of_created_nodes': 2}}\n",
      "Elapsed time: 49.06 seconds\n",
      "Estimated time remaining: 114.48 seconds\n",
      "\n",
      "Processing row 4 of 10\n",
      "Result: run_id='740f8de1-52ed-4baa-9bcc-8ba9851c5f63' result={'resolver': {'number_of_nodes_to_resolve': 19, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 69.82 seconds\n",
      "Estimated time remaining: 104.73 seconds\n",
      "\n",
      "Processing row 5 of 10\n",
      "Result: run_id='602df7a3-41df-4389-a981-bb7d807d1013' result={'resolver': {'number_of_nodes_to_resolve': 25, 'number_of_created_nodes': 2}}\n",
      "Elapsed time: 84.34 seconds\n",
      "Estimated time remaining: 84.34 seconds\n",
      "\n",
      "Processing row 6 of 10\n",
      "Result: run_id='f36d21f1-0988-49ee-9e90-7879cd81ff80' result={'resolver': {'number_of_nodes_to_resolve': 30, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 99.28 seconds\n",
      "Estimated time remaining: 66.18 seconds\n",
      "\n",
      "Processing row 7 of 10\n",
      "Result: run_id='34b7b4cb-6c03-4e91-9f61-4a21e7a0a191' result={'resolver': {'number_of_nodes_to_resolve': 33, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 117.16 seconds\n",
      "Estimated time remaining: 50.21 seconds\n",
      "\n",
      "Processing row 8 of 10\n",
      "Result: run_id='bd32a690-0fd2-477b-879c-f4c25c03eba8' result={'resolver': {'number_of_nodes_to_resolve': 41, 'number_of_created_nodes': 4}}\n",
      "Elapsed time: 129.03 seconds\n",
      "Estimated time remaining: 32.26 seconds\n",
      "\n",
      "Processing row 9 of 10\n",
      "Result: run_id='3cf78116-31e1-4aae-a609-54621b141840' result={'resolver': {'number_of_nodes_to_resolve': 41, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 146.83 seconds\n",
      "Estimated time remaining: 16.31 seconds\n",
      "\n",
      "Processing row 10 of 10\n",
      "Result: run_id='878eb587-2c1c-4942-8733-f9ce343bda81' result={'resolver': {'number_of_nodes_to_resolve': 48, 'number_of_created_nodes': 5}}\n",
      "Elapsed time: 159.95 seconds\n",
      "Estimated time remaining: 0.00 seconds\n",
      "\n",
      "Processing the second dataframe...\n",
      "Processing row 1 of 15\n",
      "Result: run_id='93eba44b-5119-44cd-ada6-fa3e94461dae' result={'resolver': {'number_of_nodes_to_resolve': 44, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 2.34 seconds\n",
      "Estimated time remaining: 32.83 seconds\n",
      "\n",
      "Processing row 2 of 15\n",
      "Result: run_id='fa54127d-8416-41c2-8333-d7361cfc6161' result={'resolver': {'number_of_nodes_to_resolve': 45, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 7.63 seconds\n",
      "Estimated time remaining: 49.58 seconds\n",
      "\n",
      "Processing row 3 of 15\n",
      "Result: run_id='28e51c70-e746-428a-b613-522009be2377' result={'resolver': {'number_of_nodes_to_resolve': 46, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 11.08 seconds\n",
      "Estimated time remaining: 44.33 seconds\n",
      "\n",
      "Processing row 4 of 15\n",
      "Result: run_id='3fca9607-3083-4880-91cb-3a8db017a45e' result={'resolver': {'number_of_nodes_to_resolve': 46, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 14.00 seconds\n",
      "Estimated time remaining: 38.51 seconds\n",
      "\n",
      "Processing row 5 of 15\n",
      "Result: run_id='6239b831-af76-4f21-9258-97ec4956f09a' result={'resolver': {'number_of_nodes_to_resolve': 46, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 16.26 seconds\n",
      "Estimated time remaining: 32.52 seconds\n",
      "\n",
      "Processing row 6 of 15\n",
      "Result: run_id='e4f165ad-31f9-459c-8a61-86251d1f6cb7' result={'resolver': {'number_of_nodes_to_resolve': 46, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 18.66 seconds\n",
      "Estimated time remaining: 27.99 seconds\n",
      "\n",
      "Processing row 7 of 15\n",
      "Result: run_id='bc51a2a1-3377-4063-99a3-b01a1209f841' result={'resolver': {'number_of_nodes_to_resolve': 46, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 22.03 seconds\n",
      "Estimated time remaining: 25.17 seconds\n",
      "\n",
      "Processing row 8 of 15\n",
      "Result: run_id='cf0ab2d1-3990-40e1-a34c-d33873fd82b1' result={'resolver': {'number_of_nodes_to_resolve': 46, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 25.15 seconds\n",
      "Estimated time remaining: 22.00 seconds\n",
      "\n",
      "Processing row 9 of 15\n",
      "Result: run_id='f3f5a74b-0c5d-4c4e-aee5-5b073868dd98' result={'resolver': {'number_of_nodes_to_resolve': 47, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 29.13 seconds\n",
      "Estimated time remaining: 19.42 seconds\n",
      "\n",
      "Processing row 10 of 15\n",
      "Result: run_id='697cd694-f457-4347-847c-90b89501f22e' result={'resolver': {'number_of_nodes_to_resolve': 47, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 31.47 seconds\n",
      "Estimated time remaining: 15.73 seconds\n",
      "\n",
      "Processing row 11 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "].\n",
      "LLM response has improper format for chunk_index=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: run_id='df66005a-d949-4c9d-8b0e-d19b5bf5e181' result={'resolver': {'number_of_nodes_to_resolve': 47, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 34.10 seconds\n",
      "Estimated time remaining: 12.40 seconds\n",
      "\n",
      "Processing row 12 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "].\n",
      "LLM response has improper format for chunk_index=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: run_id='50622147-54c3-4820-b5bd-55a8e5097ebf' result={'resolver': {'number_of_nodes_to_resolve': 47, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 36.70 seconds\n",
      "Estimated time remaining: 9.18 seconds\n",
      "\n",
      "Processing row 13 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "].\n",
      "LLM response has improper format for chunk_index=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: run_id='4cba2cc0-c28c-41b4-8725-be06dd493315' result={'resolver': {'number_of_nodes_to_resolve': 47, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 39.28 seconds\n",
      "Estimated time remaining: 6.04 seconds\n",
      "\n",
      "Processing row 14 of 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "].\n",
      "LLM response has improper format for chunk_index=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: run_id='9540a96c-06b2-46b4-9b42-6f728541658f' result={'resolver': {'number_of_nodes_to_resolve': 47, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 41.86 seconds\n",
      "Estimated time remaining: 2.99 seconds\n",
      "\n",
      "Processing row 15 of 15\n",
      "Result: run_id='cfa29aaf-0289-40bf-8031-f45e9f73e394' result={'resolver': {'number_of_nodes_to_resolve': 48, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 47.50 seconds\n",
      "Estimated time remaining: 0.00 seconds\n",
      "\n",
      "Processed 25 documents\n"
     ]
    }
   ],
   "source": [
    "# Example usage code\n",
    "async def build_knowledge_graph():\n",
    "    \"\"\"Main function to build knowledge graph from ACLED data.\"\"\"\n",
    "\n",
    "    global df1, df2\n",
    "    \n",
    "    # Find path to config_files folder\n",
    "    config_files_path = os.path.join(os.path.dirname(os.getcwd()), 'config_files')\n",
    "    load_dotenv(os.path.join(config_files_path, '.env'), override=True)\n",
    "    \n",
    "    with open(os.path.join(config_files_path, 'kg_building_config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Get credentials\n",
    "    neo4j_uri = os.getenv('NEO4J_URI')\n",
    "    neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "    neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "    if not all([neo4j_uri, neo4j_username, neo4j_password, gemini_api_key]):\n",
    "        raise ValueError(\"Missing required environment variables\")\n",
    "\n",
    "    # Load and prepare data\n",
    "    file_path = os.path.join(os.path.dirname(os.getcwd()), 'data', 'acled', 'Acled_Sudan_2025-05-01_2025-05-31.parquet')\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "\n",
    "    df = pl.read_parquet(file_path).head(10)\n",
    "\n",
    "    # Convert date column to string format\n",
    "    if 'date' in df.columns:\n",
    "        df = df.with_columns([\n",
    "            pl.col('date').dt.strftime('%Y-%m-%d').alias('date')\n",
    "        ])\n",
    "\n",
    "    print(f\"Processing {len(df)} documents...\")\n",
    "\n",
    "    # Initialize components\n",
    "    llm = GeminiLLM(\n",
    "        model_name=config['llm_config']['model_name'],\n",
    "        google_api_key=gemini_api_key,\n",
    "        model_params=config['llm_config']['model_params']\n",
    "    )\n",
    "\n",
    "    embedder = SentenceTransformerEmbeddings(model=config['embedder_config']['model_name'])\n",
    "\n",
    "    # Build knowledge graph\n",
    "    with neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password)) as driver:\n",
    "\n",
    "        # Initialize entity resolver\n",
    "        resolver = SpaCySemanticMatchResolver(\n",
    "            driver,\n",
    "            filter_query=None,\n",
    "            resolve_properties=[\"name\"],\n",
    "            similarity_threshold=0.95,\n",
    "            spacy_model=\"en_core_web_lg\"\n",
    "        )\n",
    "\n",
    "        # Initialize KG pipeline\n",
    "        kg_pipeline = CustomKGPipeline(\n",
    "            llm=llm,\n",
    "            driver=driver,\n",
    "            embedder=embedder,\n",
    "            schema_config=config['schema_config'],\n",
    "            prompt_template=config['prompt_template_config']['template'] if not config['prompt_template_config'].get('use_default', True) else None,\n",
    "            text_splitter_config=config['text_splitter_config'],\n",
    "            resolver=resolver,\n",
    "            examples_config=None,\n",
    "            on_error='RAISE',\n",
    "            batch_size=1000,\n",
    "            max_concurrency=5\n",
    "        )\n",
    "\n",
    "        # Define document metadata mapping\n",
    "        document_metadata_mapping = {\n",
    "            'date': 'date',\n",
    "            'url': 'url',\n",
    "            'domain': 'domain'\n",
    "        }\n",
    "        \n",
    "        metadata_mapping2 = {\n",
    "            \"name\": \"Text\",\n",
    "            \"location\": \"Text\",\n",
    "            \"adm1\": \"Admin1\",\n",
    "            \"country\": \"Country\"\n",
    "        }\n",
    "        \n",
    "        # Process the First dataframe\n",
    "        print(\"Processing the first dataframe...\")\n",
    "        results_df1 = await build_kg_from_df(\n",
    "            kg_pipeline=kg_pipeline,\n",
    "            df=df1,\n",
    "            document_base_field='id',\n",
    "            text_column='Text',\n",
    "            document_metadata_mapping=metadata_mapping1,\n",
    "            document_id_column=None  # Use default document ID generation\n",
    "        )\n",
    "        all_results.extend(results_df1)\n",
    "\n",
    "        # Process the Second dataframe\n",
    "        print(\"Processing the second dataframe...\")\n",
    "        results_df2 = await build_kg_from_df(\n",
    "            kg_pipeline=kg_pipeline,\n",
    "            df=df2,\n",
    "            document_base_field='id',\n",
    "            text_column='Text',\n",
    "            document_metadata_mapping=metadata_mapping2,\n",
    "            document_id_column=None  # Use default document ID generation\n",
    "        )\n",
    "        all_results.extend(results_df2)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "    return results\n",
    "\n",
    "# Execute pipeline\n",
    "print(\"🚀 Starting Knowledge Graph construction...\")\n",
    "all_results = await build_knowledge_graph()\n",
    "print(f\"✅ Processed {len(all_results)} documents successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67cb35f",
   "metadata": {},
   "source": [
    "# 3. Entity Resolution and Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOC is available.\n",
      "Found 48 entities to process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f943dfa466a42c4ad137310e41c7486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing similarity scores:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 similar entity pairs.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv(\"NEO4J_URI\"),\n",
    "    auth=(\"neo4j\", os.getenv(\"NEO4J_PASSWORD\"))\n",
    ")\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "# List of relevant node labels for deduplication\n",
    "ENTITY_LABELS = [\"Event\", \"Actor\", \"Country\", \"ADM1\", \"Location\"]\n",
    "\n",
    "def get_all_entities():\n",
    "    \"\"\"Retrieve all entities from the knowledge graph.\"\"\"\n",
    "    all_entities = []\n",
    "    query_template = \"\"\"\n",
    "    MATCH (n:{label})\n",
    "    RETURN elementId(n) AS id, n.name AS name, labels(n) AS labels, properties(n) AS properties\n",
    "    \"\"\"\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        for label in ENTITY_LABELS:\n",
    "            result = session.run(query_template.format(label=label)).data()\n",
    "            all_entities.extend(result)\n",
    "    \n",
    "    return all_entities\n",
    "\n",
    "def find_similar_entities(threshold=0.7):\n",
    "    \"\"\"Find and create relationships between similar entities.\"\"\"\n",
    "    entities = get_all_entities()\n",
    "    print(f\"Processing {len(entities)} entities...\")\n",
    "    \n",
    "    # Generate embeddings for each entity\n",
    "    for entity in entities:\n",
    "        # Filter entity labels\n",
    "        filtered_labels = [l for l in entity['labels'] if l not in [\"__KGBuilder__\", \"__Entity__\"]]\n",
    "        entity['primary_label'] = filtered_labels[0] if filtered_labels else entity['labels'][0]\n",
    "        \n",
    "        # Create text representation for embedding\n",
    "        text = f\"Type: {entity['primary_label']}\\nName: {entity['name']}\\n\"\n",
    "        for key, value in entity['properties'].items():\n",
    "            if key != 'embedding' and value is not None:\n",
    "                text += f\"{key}: {str(value)}\\n\"\n",
    "        \n",
    "        entity['embedding'] = get_embedding(text)\n",
    "    \n",
    "    # Find similar pairs\n",
    "    similar_pairs = []\n",
    "    for i, e1 in enumerate(entities):\n",
    "        for j, e2 in enumerate(entities[i + 1:], i + 1):\n",
    "            # Only compare entities with same label\n",
    "            if e1['primary_label'] != e2['primary_label']:\n",
    "                continue\n",
    "            \n",
    "            similarity = cosine_similarity(e1['embedding'], e2['embedding'])\n",
    "            if similarity > threshold:\n",
    "                similar_pairs.append({\n",
    "                    \"id1\": e1['id'],\n",
    "                    \"id2\": e2['id'],\n",
    "                    \"name1\": e1['name'],\n",
    "                    \"name2\": e2['name'],\n",
    "                    \"type1\": e1['primary_label'],\n",
    "                    \"type2\": e2['primary_label'],\n",
    "                    \"similarity\": similarity\n",
    "                })\n",
    "    \n",
    "    # Create SAME_AS relationships\n",
    "    create_query = \"\"\"\n",
    "    MATCH (a), (b)\n",
    "    WHERE elementId(a) = $id1 AND elementId(b) = $id2\n",
    "    MERGE (a)-[:SAME_AS {similarity: $similarity}]->(b)\n",
    "    \"\"\"\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        for pair in tqdm.tqdm(similar_pairs, desc=\"Creating similarity relationships\"):\n",
    "            session.run(create_query, pair)\n",
    "    \n",
    "    return similar_pairs\n",
    "\n",
    "def merge_similar_nodes():\n",
    "    merge_query = \"\"\"\n",
    "    MATCH (n1)-[r:SAME_AS]->(n2)\n",
    "    WHERE n1 IS NOT NULL AND n2 IS NOT NULL AND r.similarity >= $threshold\n",
    "    \n",
    "    // Copy properties from n2 to n1 if they don't exist\n",
    "    WITH n1, n2, [key IN keys(n2) WHERE NOT key IN keys(n1)] AS newKeys\n",
    "    FOREACH (key IN newKeys | SET n1[key] = n2[key])\n",
    "    \n",
    "    // Transfer outgoing relationships\n",
    "    WITH n1, n2\n",
    "    OPTIONAL MATCH (n2)-[outRel]->(target)\n",
    "    WHERE target IS NOT NULL AND type(outRel) <> 'SAME_AS'\n",
    "    WITH n1, n2, outRel, target, type(outRel) AS relType\n",
    "    WHERE NOT EXISTS((n1)-[:`${relType}`]->(target))\n",
    "    FOREACH (_ IN CASE WHEN outRel IS NOT NULL THEN [1] ELSE [] END |\n",
    "        CREATE (n1)-[newRel:`${relType}`]->(target)\n",
    "        SET newRel = properties(outRel)\n",
    "    )\n",
    "    \n",
    "    // Transfer incoming relationships\n",
    "    WITH DISTINCT n1, n2\n",
    "    OPTIONAL MATCH (source)-[inRel]->(n2)\n",
    "    WHERE source IS NOT NULL AND source <> n1 AND type(inRel) <> 'SAME_AS'\n",
    "    WITH n1, n2, inRel, source, type(inRel) AS relType\n",
    "    WHERE NOT EXISTS((source)-[:`${relType}`]->(n1))\n",
    "    FOREACH (_ IN CASE WHEN inRel IS NOT NULL THEN [1] ELSE [] END |\n",
    "        CREATE (source)-[newRel:`${relType}`]->(n1)\n",
    "        SET newRel = properties(inRel)\n",
    "    )\n",
    "    \n",
    "    // Delete the duplicate node\n",
    "    WITH DISTINCT n1, n2\n",
    "    DETACH DELETE n2\n",
    "    RETURN count(n2) AS mergedCount\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(merge_query, {\"threshold\": threshold})\n",
    "            record = result.single()\n",
    "            return record[\"mergedCount\"] if record else 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error during node merging: {e}\")\n",
    "        return 0\n",
    "\n",
    "def check_apoc():\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            session.run(\"CALL apoc.help('create')\")\n",
    "            print(\"APOC is available.\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"APOC not available: {e}\")\n",
    "        return False\n",
    "\n",
    "# === MAIN EXECUTION ===\n",
    "check_apoc()\n",
    "pairs = find_similar_entities()\n",
    "pairs = sorted(pairs, key=lambda x: x[\"similarity\"], reverse=True)\n",
    "print(f\"Found {len(pairs)} similar entity pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be4205df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:227', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:282', 'name1': 'Kutum', 'name2': 'Kubum', 'type1': 'Location', 'type2': 'Location', 'similarity': np.float64(0.9554210593764909)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:19', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:368', 'name1': 'military', 'name2': 'army', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9545791105950588)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:4', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:53', 'name1': 'Sudan doctors union', 'name2': 'Sudan Doctors Network', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9404681965196532)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:47', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:105', 'name1': 'Cholera outbreak', 'name2': 'cholera-related deaths and infections', 'type1': 'Event', 'type2': 'Event', 'similarity': np.float64(0.9379905887483682)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:22', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:71', 'name1': 'Sudanese government', 'name2': 'Sudan health authorities', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9242922749244303)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:0', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:47', 'name1': '727 cholera cases', 'name2': 'Cholera outbreak', 'type1': 'Event', 'type2': 'Event', 'similarity': np.float64(0.9226276889101158)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:0', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:105', 'name1': '727 cholera cases', 'name2': 'cholera-related deaths and infections', 'type1': 'Event', 'type2': 'Event', 'similarity': np.float64(0.9214347261225326)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:189', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:355', 'name1': 'Bahri', 'name2': 'Bahr Al Arab', 'type1': 'Location', 'type2': 'Location', 'similarity': np.float64(0.9054276767911795)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:4', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:71', 'name1': 'Sudan doctors union', 'name2': 'Sudan health authorities', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.902051708901004)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:43', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:147', 'name1': 'WHO', 'name2': 'WFP', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9019962818021556)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:605', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:639', 'name1': 'Formation of New Government', 'name2': 'Government Dissolution', 'type1': 'Event', 'type2': 'Event', 'similarity': np.float64(0.9018204702396523)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:6', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:100', 'name1': 'an adult', 'name2': '70 people', 'type1': 'Actor', 'type2': 'Actor', 'similarity': np.float64(0.9009297165393891)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:151', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:195', 'name1': 'Kassala', 'name2': 'Karrari', 'type1': 'Location', 'type2': 'Location', 'similarity': np.float64(0.9003306986191377)}]\n"
     ]
    }
   ],
   "source": [
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_similar_nodes()\n",
    "print(f\"Merged {merged} nodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c57305",
   "metadata": {},
   "source": [
    "### Node similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge similar entities with high similarity threshold\n",
    "print(\"🔄 Merging similar entities...\")\n",
    "merged_count = merge_similar_nodes(threshold=0.89)\n",
    "print(f\"✅ Successfully merged {merged_count} duplicate nodes\")\n",
    "\n",
    "# Close the driver connection\n",
    "if 'driver' in locals():\n",
    "    driver.close()\n",
    "    print(\"📝 Database connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3518f28",
   "metadata": {},
   "source": [
    "# 4. Summary\n",
    "\n",
    "This notebook demonstrated the complete pipeline for building and refining a knowledge graph:\n",
    "\n",
    "1. **Data Loading**: Loaded ACLED conflict data from Sudan\n",
    "2. **Knowledge Graph Construction**: Created entities, relationships, and document nodes with metadata\n",
    "3. **Entity Resolution**: Found similar entities using embedding-based similarity\n",
    "4. **Deduplication**: Merged duplicate entities to create a cleaner graph\n",
    "\n",
    "The resulting knowledge graph contains deduplicated entities with proper relationships, ready for downstream analysis and querying."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
