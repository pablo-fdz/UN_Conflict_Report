{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c77816e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import polars as pl\n",
    "import re\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97823bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "factal_api_key = os.getenv('FACTAL_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b6b958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(country, kind=None, category=None):\n",
    "    \"\"\"\n",
    "    Get the topic ID for a given location name from the Factal API.\n",
    "    Args:\n",
    "        country (str): Name of the location to search for (e.g., \"West Kordofan, Sudan\" or \"Sudan\")\n",
    "        kind (str): Topics are categorized predominantly into three kinds: \"tag\", \"arc\" and \"location\". The most common topic kind is \"location\"\n",
    "        category (str): Location categories in order of granularity: \"POI\", \"Airport\", \"Suburb\", \"Town\", \"Township\", \"NaturalFeature\", \"County\", \"State\", \"Colloquial\", \"Country\"\n",
    "    Returns:\n",
    "        int or None: The topic ID if found, None otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://www.factal.com/api/v2/topic/\"\n",
    "    params = {\n",
    "        \"name\": country,\n",
    "        \"kind\": kind,\n",
    "        \"category\": category\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Token {factal_api_key}'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        if 'results' in data and len(data['results']) > 0:\n",
    "            topic_id = data['results'][0]['id']\n",
    "            print(f\"Topic ID for {country}: {topic_id}\")\n",
    "            return topic_id\n",
    "        else:\n",
    "            print(f\"No results found for {country}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making API request: {e}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing JSON response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048e6f4",
   "metadata": {},
   "source": [
    "## Set up the country keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c1e2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"papua new guinea\"  # Example country name\n",
    "country = country.lower().title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c4f50f",
   "metadata": {},
   "source": [
    "## Get news items with location code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49b4bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(country=country, kind=None, category=None):\n",
    "    \"\"\"\n",
    "    Get the topic ID for a given location name from the Factal API.\n",
    "    Args:\n",
    "        country (str): Name of the location to search for (e.g., \"West Kordofan, Sudan\" or \"Sudan\")\n",
    "        kind (str): Topics are categorized predominantly into three kinds: \"tag\", \"arc\" and \"location\". The most common topic kind is \"location\"\n",
    "        category (str): Location categories in order of granularity: \"POI\", \"Airport\", \"Suburb\", \"Town\", \"Township\", \"NaturalFeature\", \"County\", \"State\", \"Colloquial\", \"Country\"\n",
    "    Returns:\n",
    "        int or None: The topic ID if found, None otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://www.factal.com/api/v2/topic/\"\n",
    "    params = {\n",
    "        \"name\": country,\n",
    "        \"kind\": kind,\n",
    "        \"category\": category\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Token {factal_api_key}'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        if 'results' in data and len(data['results']) > 0:\n",
    "            topic_id = data['results'][0]['id']\n",
    "            print(f\"Topic ID for {country}: {topic_id}\")\n",
    "            return topic_id\n",
    "        else:\n",
    "            print(f\"No results found for {country}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making API request: {e}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing JSON response: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_items_for_topic(country=country, kind=None, category=None, topic_id=None, page_size=100, limit=None, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Retrieve items for a given topic from the Factal API.\n",
    "    \n",
    "    Args:\n",
    "        country (str, optional): Name of the topic location to search for (e.g., \"Sudan\")\n",
    "        kind (str): Topics are categorized predominantly into three kinds: \"tag\", \"arc\" and \"location\". The most common topic kind is \"location\"\n",
    "        category (str): Location categories in order of granularity: \"POI\", \"Airport\", \"Suburb\", \"Town\", \"Township\", \"NaturalFeature\", \"County\", \"State\", \"Colloquial\", \"Country\"\n",
    "        topic_id (int, optional): Topic ID if already known\n",
    "        page_size (int): Number of items per page (max 100)\n",
    "        limit (int, optional): Maximum number of items to retrieve\n",
    "        start_date (str, optional): ISO date format (YYYY-MM-DD) to filter items from\n",
    "        end_date (str, optional): ISO date format (YYYY-MM-DD) to filter items until\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing all items\n",
    "    \"\"\"\n",
    "    \n",
    "    # If we don't have a topic_id but have a name, get the ID first\n",
    "    if topic_id is None and country is not None:\n",
    "        topic_id = get_id(country, kind, category)\n",
    "        if topic_id is None:\n",
    "            print(f\"Topic ID for {country} not found.\")\n",
    "            return pl.DataFrame()  # Return empty dataframe if topic not found\n",
    "    elif country is not None and topic_id is not None:\n",
    "        print(\"Both country and topic_id provided. Using topic_id.\")\n",
    "    \n",
    "    if topic_id is None:\n",
    "        print(\"Error: Either country or topic_id must be provided\")\n",
    "        return pl.DataFrame()\n",
    "        \n",
    "    # Base URL for items endpoint\n",
    "    url = 'https://www.factal.com/api/v2/item/'\n",
    "    \n",
    "    # Set up parameters\n",
    "    params = {\n",
    "        'topics': str(topic_id),\n",
    "        'kind': str(kind) if kind else None,\n",
    "        'category': str(category) if kind and category else None,\n",
    "        'page_size': page_size\n",
    "    }\n",
    "    \n",
    "    # Add optional date filter if provided\n",
    "    if start_date:\n",
    "        params['date__gte'] = start_date\n",
    "        \n",
    "    if start_date and end_date:\n",
    "        params['date__range'] = f\"{start_date},{end_date}\"\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Token {factal_api_key}'\n",
    "    }\n",
    "    \n",
    "    all_results = []\n",
    "    next_url = url\n",
    "    items_retrieved = 0\n",
    "    \n",
    "    try:\n",
    "        while next_url:\n",
    "            print(f\"Fetching data from: {next_url}\")\n",
    "            response = requests.get(next_url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            results = data.get('results', [])\n",
    "            all_results.extend(results)\n",
    "            \n",
    "            items_retrieved += len(results)\n",
    "            print(f\"Retrieved {len(results)} items. Total: {items_retrieved}\")\n",
    "            \n",
    "            # Check if we've reached the limit\n",
    "            if limit and items_retrieved >= limit:\n",
    "                all_results = all_results[:limit]\n",
    "                break\n",
    "                \n",
    "            # Get the next page URL\n",
    "            next_url = data.get('next')\n",
    "            \n",
    "            # If moving to next page, we don't need params anymore (they're in the URL)\n",
    "            if next_url:\n",
    "                params = {}\n",
    "            \n",
    "        # Convert to DataFrame\n",
    "        df = pl.DataFrame(all_results)\n",
    "        return df\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making API request: {e}\")\n",
    "        return pl.DataFrame(all_results) if all_results else pl.DataFrame()\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing JSON response: {e}\")\n",
    "        return pl.DataFrame(all_results) if all_results else pl.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35eae89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic ID for Papua New Guinea: 48816\n",
      "Fetching data from: https://www.factal.com/api/v2/item/\n",
      "Retrieved 32 items. Total: 32\n"
     ]
    }
   ],
   "source": [
    "# Get only items starting from 2025\n",
    "news_items = get_items_for_topic(\n",
    "    country=country,\n",
    "    topic_id=None,\n",
    "    kind=\"location\", # None / \"location\" / \"arc\" / \"tag\"\n",
    "    category=\"Country\", # None / \"POI\" / \"Country\" / \"State\" / \"Town\" / \"Township\" / \"Suburb\" / \"NaturalFeature\" / \"Colloquial\" / \"Airport\"\n",
    "    start_date=\"2025-01-01\",\n",
    "    end_date=\"2025-06-27\", # last day not included\n",
    "    limit=None # None or int, if set, will limit the number of items returned\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3538836",
   "metadata": {},
   "source": [
    "## Extract topics for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca2d16bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'topics' not found in DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 0)</small><table border=\"1\" class=\"dataframe\"><thead><tr></tr><tr></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 0)\n",
       "┌┐\n",
       "╞╡\n",
       "└┘"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the topics column into a separate DataFrame\n",
    "def extract_topics_to_df(df, column):\n",
    "    # Create a list to store all topics\n",
    "    all_topics = []\n",
    "    \n",
    "    # Check if column exists\n",
    "    if column not in df.columns:\n",
    "        print(f\"Error: '{column}' not found in DataFrame\")\n",
    "        return pl.DataFrame()\n",
    "    \n",
    "    # Iterate through each row in the original DataFrame using polars approach\n",
    "    for row in df.iter_rows(named=True):\n",
    "        topics_list = row[column]\n",
    "        if not topics_list:\n",
    "            continue\n",
    "        for topic in topics_list:\n",
    "            topic_dict = dict(topic)\n",
    "            topic_dict['item_id'] = row['id']\n",
    "            all_topics.append(topic_dict)\n",
    "    \n",
    "    # Normalize the 'topic' field and keep 'item_id'\n",
    "    if not all_topics:\n",
    "        return pl.DataFrame()\n",
    "    \n",
    "    topics_df = pl.DataFrame(all_topics)\n",
    "    \n",
    "    # Extract topic data - polars doesn't have json_normalize, so we extract fields directly\n",
    "    if 'topic' in topics_df.columns:\n",
    "        # Extract fields from the topic dictionary\n",
    "        topic_data = []\n",
    "        for topic in topics_df['topic'].to_list():\n",
    "            topic_data.append(topic)\n",
    "        \n",
    "        # Create a DataFrame from the extracted topic data\n",
    "        topics_flat = pl.DataFrame(topic_data)\n",
    "        # Add item_id from the original topics_df\n",
    "        topics_flat = topics_flat.with_columns(topics_df['item_id'])\n",
    "        columns = ['item_id'] + [col for col in topics_flat.columns if col != 'item_id']\n",
    "        topics_flat = topics_flat.select(columns)\n",
    "        return topics_flat\n",
    "    else:\n",
    "        return topics_df\n",
    "\n",
    "# Create the topics DataFrame\n",
    "topics_df = extract_topics_to_df(news_items, \"topics\")\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eee962",
   "metadata": {},
   "source": [
    "## Merge DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e47af3fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "id",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mColumnNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m items_merged = \u001b[43mnews_items\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mitem_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\Master_Thesis\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\polars\\_utils\\deprecation.py:128\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    125\u001b[39m     _rename_keyword_argument(\n\u001b[32m    126\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    127\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\Master_Thesis\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\polars\\dataframe\\frame.py:7842\u001b[39m, in \u001b[36mDataFrame.join\u001b[39m\u001b[34m(self, other, on, how, left_on, right_on, suffix, validate, nulls_equal, coalesce, maintain_order)\u001b[39m\n\u001b[32m   7824\u001b[39m require_same_type(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m   7826\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazyframe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopt_flags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QueryOptFlags\n\u001b[32m   7828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   7829\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7830\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7831\u001b[39m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m=\u001b[49m\u001b[43mother\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7832\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7833\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7836\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7837\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7838\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnulls_equal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnulls_equal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7839\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoalesce\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoalesce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaintain_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaintain_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7841\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m7842\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mQueryOptFlags\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_eager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7843\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\Master_Thesis\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\polars\\_utils\\deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\Master_Thesis\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\polars\\lazyframe\\opt_flags.py:331\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    328\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    330\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\Master_Thesis\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2300\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2298\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2299\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2300\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mColumnNotFoundError\u001b[39m: id"
     ]
    }
   ],
   "source": [
    "items_merged = news_items.join(topics_df, left_on='id', right_on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d520f9",
   "metadata": {},
   "source": [
    "## Fill missing url, get full Twitter url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf93a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_merged = items_merged.with_columns(\n",
    "    pl.when((pl.col('url')=='') & (pl.col('url_domain')=='x.com'))\n",
    "    .then(pl.col('source') + pl.lit('/status/') + pl.col('tweet_id').cast(pl.Utf8))\n",
    "    .otherwise(pl.col('url'))\n",
    "    .alias('url')\n",
    ")\n",
    "\n",
    "items_merged = items_merged.with_columns(\n",
    "    (pl.lit(\"factal_\") + pl.col(\"id\").cast(pl.Utf8)).alias(\"item_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca90dd5",
   "metadata": {},
   "source": [
    "## Drop some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = items_merged.select([\n",
    "    pl.col('item_id'),\n",
    "    pl.col('url'),\n",
    "    pl.col('content').alias('text'),\n",
    "    pl.col('source').alias('domain'),\n",
    "    pl.col('date').str.to_datetime().dt.date(),  # Convert string to datetime first, then extract date\n",
    "    pl.col('severity'),\n",
    "    pl.col('name').alias('topic'),\n",
    "    pl.col('kind'),\n",
    "    pl.col('category'),\n",
    "    pl.col('description').alias('topic_summary')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_categories(df):\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"category\") == \"Country\")\n",
    "        .then(pl.col(\"topic\"))\n",
    "        .otherwise(None)\n",
    "        .alias(\"country\")\n",
    "    )\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"category\") == \"State\")\n",
    "        .then(pl.col(\"topic\"))\n",
    "        .otherwise(None)\n",
    "        .alias(\"state\")\n",
    "    )\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"category\") == \"State\")\n",
    "        .then(pl.col(\"topic\"))\n",
    "        .otherwise(None)\n",
    "        .alias(\"state\")\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"category\") == \"Town\")\n",
    "        .then(pl.col(\"topic\"))\n",
    "        .otherwise(None)\n",
    "        .alias(\"town\")\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"category\") == \"POI\")\n",
    "        .then(pl.col(\"topic\"))\n",
    "        .otherwise(None)\n",
    "        #.str.extract(r\", (.+)\", 1) # regex to clean location names like \"2QQ2+257, Muglad, Sudan\"\n",
    "        .alias(\"location\")\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"kind\") == \"arc\")\n",
    "        .then(pl.col(\"topic\"))\n",
    "        .otherwise(None)\n",
    "        .str.replace(r\" at \\w+\\+\\w+, \", \" at \")\n",
    "        .str.replace(r\"^\\w+\\+\\w+\\s\", \"\")\n",
    "        .alias(\"topic2\")\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"kind\") == \"vertical\")\n",
    "        .then(pl.col(\"topic\"))\n",
    "        .otherwise(None)\n",
    "        .alias(\"theme\")\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"kind\") == \"tag\")\n",
    "        .then(pl.col(\"topic\"))\n",
    "        .otherwise(None)\n",
    "        .alias(\"tag\")\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "clean_df = fill_categories(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_factal_id(df):\n",
    "\t\"\"\"\n",
    "\tGroup the dataframe by item_id and combine relevant columns\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tdf: polars DataFrame with multiple rows per item_id\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tpolars DataFrame with one row per item_id\n",
    "\t\"\"\"\n",
    "\t# Get unique factal_ids\n",
    "\tunique_ids = df.select(pl.col(\"item_id\")).unique()\n",
    "\t\n",
    "\tresult_rows = []\n",
    "\t\n",
    "\t# For each unique ID, collect all values\n",
    "\tfor row in unique_ids.iter_rows(named=True):\n",
    "\t\titem_id = row[\"item_id\"]\n",
    "\t\t\n",
    "\t\t# Filter data for this specific ID\n",
    "\t\tid_data = df.filter(pl.col(\"item_id\") == item_id)\n",
    "\t\t\n",
    "\t\t# Get first value for columns that should be the same for all rows with this ID\n",
    "\t\tfirst_row = id_data.row(0, named=True)\n",
    "\t\t\n",
    "\t\t# Create a new row with combined data\n",
    "\t\tnew_row = {\n",
    "\t\t\t\"item_id\": item_id,\n",
    "\t\t\t\"url\": first_row[\"url\"],\n",
    "\t\t\t\"text\": first_row[\"text\"],\n",
    "\t\t\t\"domain\": first_row[\"domain\"],\n",
    "\t\t\t\"date\": first_row[\"date\"],\n",
    "\t\t\t\"severity\": first_row[\"severity\"],\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\t# Combine categorical fields (non-null values only)\n",
    "\t\tfor col in [\"country\", \"state\", \"town\", \"location\", \"topic2\", \"theme\", \"tag\"]:\n",
    "\t\t\tvalues = id_data.select(pl.col(col)).filter(pl.col(col).is_not_null()).unique().to_series().to_list()\n",
    "\t\t\tnew_row[col] = values[0] if values else None\n",
    "\n",
    "\t\t# Extract country from state if possible\n",
    "\t\tstate_val = new_row.get(\"state\")\n",
    "\t\tcountry_val = new_row.get(\"country\")\n",
    "\n",
    "\t\tif state_val is not None:\n",
    "\t\t\tif isinstance(state_val, list):\n",
    "\t\t\t\tstate_str = next((s for s in state_val if isinstance(s, str) and s.strip()), None)\n",
    "\t\t\telse:\n",
    "\t\t\t\tstate_str = state_val\n",
    "\n",
    "\t\t\tif isinstance(state_str, str) and ',' in state_str:\n",
    "\t\t\t\tmatch = re.search(r',\\s*([^,]+)$', state_str)\n",
    "\t\t\t\tif match:\n",
    "\t\t\t\t\tnew_row[\"country\"] = match.group(1).strip()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnew_row[\"country\"] = country_val\n",
    "\t\t\telse:\n",
    "\t\t\t\tnew_row[\"country\"] = country_val\n",
    "\t\telse:\n",
    "\t\t\tnew_row[\"country\"] = country_val\n",
    "\t\n",
    "\n",
    "\t\t# Get all unique topics\n",
    "\t\ttopics = id_data.select(pl.col(\"topic\")).unique().to_series().to_list()\n",
    "\t\tnew_row[\"topics\"] = topics\n",
    "\t\t\n",
    "\t\t# Get topic summary (use the first non-null value)\n",
    "\t\tsummaries = id_data.select(pl.col(\"topic_summary\")).filter(pl.col(\"topic_summary\").is_not_null()).to_series().to_list()\n",
    "\t\tnew_row[\"topic_summary\"] = summaries[0] if summaries else None\n",
    "\t\t\n",
    "\t\tresult_rows.append(new_row)\n",
    "\t\n",
    "\t# Convert to DataFrame\n",
    "\tresult_df = pl.DataFrame(result_rows)\n",
    "\treturn result_df\n",
    "\n",
    "# Group the dataframe by item_id\n",
    "grouped_df = group_by_factal_id(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88013c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = grouped_df.with_columns(\n",
    "    pl.lit(country).alias(\"country_keyword\")\n",
    ")\n",
    "\n",
    "grouped_df = grouped_df.rename({\"topic2\": \"topic\"})\n",
    "\n",
    "new_col_order = [\"country_keyword\"] + [col for col in grouped_df.columns if col != \"country_keyword\"]\n",
    "grouped_df = grouped_df.select(new_col_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a56f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.write_parquet(f\"Factal_{country}.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
