{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae0c9b",
   "metadata": {},
   "source": [
    "# 0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a8341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory (graphrag_pipeline) to the Python path (needed for importing\n",
    "# modules in parent directory)\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Utilities\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "import polars as pl\n",
    "from library.kg_builder import CustomKGPipeline, build_kg_from_df\n",
    "from library.kg_builder.utilities import GeminiLLM\n",
    "from neo4j_graphrag.experimental.components.resolver import (\n",
    "    SpaCySemanticMatchResolver, FuzzyMatchResolver, SinglePropertyExactMatchResolver\n",
    ")\n",
    "\n",
    "from neo4j_graphrag.embeddings import SentenceTransformerEmbeddings\n",
    "import neo4j\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Import for embedding model (if needed for entity similarity)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "# Neo4j and Neo4j GraphRAG imports\n",
    "import neo4j\n",
    "from neo4j_graphrag.embeddings import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182b7fc",
   "metadata": {},
   "source": [
    "Let's first check the available Gemini models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b114e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env', override=True)\n",
    "\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if gemini_api_key:\n",
    "    client = genai.Client(api_key=gemini_api_key)  # Configure the API key for genai\n",
    "else:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad2805",
   "metadata": {},
   "source": [
    "We also have to make sure that the corresponding SpaCy model for text embedding used at the resolving step is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43270dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'en_core_web_lg' is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "def ensure_spacy_model(model_name):\n",
    "    if importlib.util.find_spec(model_name) is None:\n",
    "        print(f\"Model '{model_name}' not found. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", model_name])\n",
    "    else:\n",
    "        print(f\"Model '{model_name}' is already installed.\")\n",
    "\n",
    "# Use it for 'en_core_web_lg'\n",
    "ensure_spacy_model(\"en_core_web_lg\")  # Model used for resolving entities in the KG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39afcd",
   "metadata": {},
   "source": [
    "# 1. Loading the data\n",
    "\n",
    "The data is loaded here as a reference, but it is loaded again inside the pipeline below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4320d1",
   "metadata": {},
   "source": [
    "## 1.2. Factal sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29a4e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>title</th><th>google_link</th><th>source</th><th>id</th><th>date</th><th>decoded_url</th><th>full_text</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Shubhanshu Shukla: Astronaut b…</td><td>&quot;https://news.google.com/rss/ar…</td><td>&quot;BBC&quot;</td><td>&quot;GN_IND26683&quot;</td><td>&quot;2025-06-26&quot;</td><td>&quot;https://www.bbc.com/news/artic…</td><td>&quot;On 26 June 2025, Astronaut bec…</td></tr><tr><td>&quot;New report: India vs. Pakistan…</td><td>&quot;https://news.google.com/rss/ar…</td><td>&quot;NewsNation&quot;</td><td>&quot;GN_IND70889&quot;</td><td>&quot;2025-06-26&quot;</td><td>&quot;https://www.newsnationnow.com/…</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌──────────────┬──────────────┬────────────┬─────────────┬────────────┬──────────────┬─────────────┐\n",
       "│ title        ┆ google_link  ┆ source     ┆ id          ┆ date       ┆ decoded_url  ┆ full_text   │\n",
       "│ ---          ┆ ---          ┆ ---        ┆ ---         ┆ ---        ┆ ---          ┆ ---         │\n",
       "│ str          ┆ str          ┆ str        ┆ str         ┆ str        ┆ str          ┆ str         │\n",
       "╞══════════════╪══════════════╪════════════╪═════════════╪════════════╪══════════════╪═════════════╡\n",
       "│ Shubhanshu   ┆ https://news ┆ BBC        ┆ GN_IND26683 ┆ 2025-06-26 ┆ https://www. ┆ On 26 June  │\n",
       "│ Shukla:      ┆ .google.com/ ┆            ┆             ┆            ┆ bbc.com/news ┆ 2025,       │\n",
       "│ Astronaut b… ┆ rss/ar…      ┆            ┆             ┆            ┆ /artic…      ┆ Astronaut   │\n",
       "│              ┆              ┆            ┆             ┆            ┆              ┆ bec…        │\n",
       "│ New report:  ┆ https://news ┆ NewsNation ┆ GN_IND70889 ┆ 2025-06-26 ┆ https://www. ┆ null        │\n",
       "│ India vs.    ┆ .google.com/ ┆            ┆             ┆            ┆ newsnationno ┆             │\n",
       "│ Pakistan…    ┆ rss/ar…      ┆            ┆             ┆            ┆ w.com/…      ┆             │\n",
       "└──────────────┴──────────────┴────────────┴─────────────┴────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'C:\\Users\\blanc\\OneDrive\\Desktop\\DSDM\\3-TFM\\REPO DE VERITAT\\UN_Conflict_Report\\graphrag_pipeline\\data\\google_news\\google_news_India_2025-06-26_2025-07-01.parquet'\n",
    "df = pl.read_parquet(path)\n",
    "df = df.head(20)\n",
    "\n",
    "if df['date'].dtype == pl.Date:\n",
    "    # Convert date column to string if it is of type Date\n",
    "    df = df.with_columns(pl.col('date').cast(pl.String))\n",
    "    \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c640450",
   "metadata": {},
   "source": [
    "### Load Admin1 locations from HDX database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646aee4",
   "metadata": {},
   "source": [
    "# 2. Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57e38df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph that will be used for creating security reports for different countries.\n",
      "\n",
      "Extract the entities (nodes) and specify their type from the following Input text.\n",
      "Also extract the relationships between these nodes. The relationship direction goes from the start node to the end node.\n",
      "\n",
      "Return result as JSON using the following format:\n",
      "{\"nodes\": [{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {\"name\": \"name of entity\" }}],\n",
      "\"relationships\": [{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {\"details\": \"Description of the relationship\"}}]}\n",
      "\n",
      "- Use only the information from the Input text. Do not add any additional information.\n",
      "- Make sure to create as many nodes and relationships as needed to offer rich context.\n",
      "- Use only the provided schema.\n",
      "\n",
      "Input text:\n",
      "{text}\n"
     ]
    }
   ],
   "source": [
    "config_files_path = os.path.join(os.path.dirname(os.getcwd()), 'config_files')\n",
    "\n",
    "with open(os.path.join(config_files_path, 'kg_building_config2.json'), 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "prompt_template = config['prompt_template_config']\n",
    "\n",
    "print((prompt_template['template']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e872a9",
   "metadata": {},
   "source": [
    "## 2.2. With a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c023659",
   "metadata": {},
   "source": [
    "### A. Using the `SpaCySemanticMatchResolver`\n",
    "\n",
    "More useful information about the resolvers can be found in the [user guide](https://neo4j.com/docs/neo4j-graphrag-python/current/user_guide_kg_builder.html#entity-resolver). Below, we use different resolvers (from the most aggressive - spaCy to the most conservative - exact matching) to get a broad overview of the performance results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30b0b9",
   "metadata": {},
   "source": [
    "### Embed Locations from list of Admin units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7af0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_uri = os.getenv('NEO4J_URI')\n",
    "neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4e9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Knowledge Graph construction...\n",
      "Processing 20 documents...\n",
      "Processing the first dataframe...\n",
      "Processing row 1 of 20\n",
      "Skipping row 1 due to empty text\n",
      "Elapsed time: 0.00 seconds\n",
      "Estimated time remaining: 0.01 seconds\n",
      "\n",
      "Processing row 2 of 20\n",
      "Result: run_id='696f47d0-3e7c-4043-a5b6-bc5b4e53f723' result={'resolver': {'number_of_nodes_to_resolve': 64, 'number_of_created_nodes': 32}}\n",
      "Elapsed time: 42.57 seconds\n",
      "Estimated time remaining: 383.17 seconds\n",
      "\n",
      "Processing row 3 of 20\n",
      "Result: run_id='118efb6b-3828-4ac6-88fa-4544f4ae81bd' result={'resolver': {'number_of_nodes_to_resolve': 68, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 98.07 seconds\n",
      "Estimated time remaining: 555.74 seconds\n",
      "\n",
      "Processing row 4 of 20\n",
      "Result: run_id='82ac0068-6a3d-4a5c-91ea-c4440382ec06' result={'resolver': {'number_of_nodes_to_resolve': 75, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 119.52 seconds\n",
      "Estimated time remaining: 478.09 seconds\n",
      "\n",
      "Processing row 5 of 20\n",
      "Result: run_id='05e196d3-8f2b-453a-9eae-bb3b15b1d50b' result={'resolver': {'number_of_nodes_to_resolve': 97, 'number_of_created_nodes': 2}}\n",
      "Elapsed time: 174.43 seconds\n",
      "Estimated time remaining: 523.29 seconds\n",
      "\n",
      "Processing row 6 of 20\n",
      "Result: run_id='b8e92cc6-cf46-4b19-a9b3-4ae872c6f704' result={'resolver': {'number_of_nodes_to_resolve': 123, 'number_of_created_nodes': 4}}\n",
      "Elapsed time: 223.58 seconds\n",
      "Estimated time remaining: 521.69 seconds\n",
      "\n",
      "Processing row 7 of 20\n",
      "Result: run_id='c6ec5973-8704-4b4a-8e3d-dff887f0932f' result={'resolver': {'number_of_nodes_to_resolve': 148, 'number_of_created_nodes': 6}}\n",
      "Elapsed time: 287.10 seconds\n",
      "Estimated time remaining: 533.19 seconds\n",
      "\n",
      "Processing row 8 of 20\n",
      "Skipping row 8 due to empty text\n",
      "Elapsed time: 287.10 seconds\n",
      "Estimated time remaining: 430.65 seconds\n",
      "\n",
      "Processing row 9 of 20\n",
      "Result: run_id='9b03dc8f-1ea9-4982-8e7a-8b4abef78d9b' result={'resolver': {'number_of_nodes_to_resolve': 174, 'number_of_created_nodes': 6}}\n",
      "Elapsed time: 331.04 seconds\n",
      "Estimated time remaining: 404.60 seconds\n",
      "\n",
      "Processing row 10 of 20\n",
      "Result: run_id='c40a5399-5532-48a8-b126-87b7385e5bf6' result={'resolver': {'number_of_nodes_to_resolve': 181, 'number_of_created_nodes': 1}}\n",
      "Elapsed time: 369.64 seconds\n",
      "Estimated time remaining: 369.64 seconds\n",
      "\n",
      "Processing row 11 of 20\n",
      "Skipping row 11 due to empty text\n",
      "Elapsed time: 369.64 seconds\n",
      "Estimated time remaining: 302.44 seconds\n",
      "\n",
      "Processing row 12 of 20\n",
      "Result: run_id='46844f59-99f6-41f1-8fa8-26eecc6824bb' result={'resolver': {'number_of_nodes_to_resolve': 209, 'number_of_created_nodes': 18}}\n",
      "Elapsed time: 427.61 seconds\n",
      "Estimated time remaining: 285.07 seconds\n",
      "\n",
      "Processing row 13 of 20\n",
      "Skipping row 13 due to empty text\n",
      "Elapsed time: 427.61 seconds\n",
      "Estimated time remaining: 230.25 seconds\n",
      "\n",
      "Processing row 14 of 20\n",
      "Result: run_id='d35f5c9b-5b5b-4ec3-b9cc-28cabe0f5562' result={'resolver': {'number_of_nodes_to_resolve': 204, 'number_of_created_nodes': 2}}\n",
      "Elapsed time: 463.91 seconds\n",
      "Estimated time remaining: 198.82 seconds\n",
      "\n",
      "Processing row 15 of 20\n",
      "Skipping row 15 due to empty text\n",
      "Elapsed time: 463.91 seconds\n",
      "Estimated time remaining: 154.64 seconds\n",
      "\n",
      "Processing row 16 of 20\n",
      "Result: run_id='78e21ab8-cdeb-4eb1-83d7-c7b6e6157ece' result={'resolver': {'number_of_nodes_to_resolve': 229, 'number_of_created_nodes': 9}}\n",
      "Elapsed time: 527.58 seconds\n",
      "Estimated time remaining: 131.90 seconds\n",
      "\n",
      "Processing row 17 of 20\n",
      "Result: run_id='52f4c133-7293-4962-b788-46dfecb6c9f2' result={'resolver': {'number_of_nodes_to_resolve': 258, 'number_of_created_nodes': 10}}\n",
      "Elapsed time: 598.43 seconds\n",
      "Estimated time remaining: 105.61 seconds\n",
      "\n",
      "Processing row 18 of 20\n",
      "Skipping row 18 due to empty text\n",
      "Elapsed time: 598.43 seconds\n",
      "Estimated time remaining: 66.49 seconds\n",
      "\n",
      "Processing row 19 of 20\n",
      "Skipping row 19 due to empty text\n",
      "Elapsed time: 598.43 seconds\n",
      "Estimated time remaining: 31.50 seconds\n",
      "\n",
      "Processing row 20 of 20\n",
      "Skipping row 20 due to empty text\n",
      "Elapsed time: 598.43 seconds\n",
      "Estimated time remaining: 0.00 seconds\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Execute pipeline\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🚀 Starting Knowledge Graph construction...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m all_results = \u001b[38;5;28;01mawait\u001b[39;00m build_knowledge_graph()\n\u001b[32m     97\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Processed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mbuild_knowledge_graph\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing the first dataframe...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m     results_df1 = \u001b[38;5;28;01mawait\u001b[39;00m build_kg_from_df(\n\u001b[32m     82\u001b[39m         kg_pipeline=kg_pipeline,\n\u001b[32m     83\u001b[39m         df=df,\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m         document_id_column=\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Use default document ID generation\u001b[39;00m\n\u001b[32m     88\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[43mall_results\u001b[49m.extend(results_df1)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n",
      "\u001b[31mNameError\u001b[39m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage code\n",
    "async def build_knowledge_graph():\n",
    "    \"\"\"Main function to build knowledge graph from ACLED data.\"\"\"\n",
    "    \n",
    "    # Find path to config_files folder\n",
    "    config_files_path = os.path.join(os.path.dirname(os.getcwd()), 'config_files')\n",
    "    load_dotenv(os.path.join(config_files_path, '.env'), override=True)\n",
    "    \n",
    "    with open(os.path.join(config_files_path, 'kg_building_config.json'), 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Get credentials\n",
    "    neo4j_uri = os.getenv('NEO4J_URI')\n",
    "    neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "    neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "    if not all([neo4j_uri, neo4j_username, neo4j_password, gemini_api_key]):\n",
    "        raise ValueError(\"Missing required environment variables\")\n",
    "\n",
    "    # Load and prepare data\n",
    "    file_path = os.path.join(os.path.dirname(os.getcwd()), 'data', 'google_news', 'google_news_Sudan_2025-05-01_2025-06-01_chunk1.parquet')\n",
    "    df = pl.read_parquet(file_path)\n",
    "      \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "    \n",
    "    df = df.head(20)\n",
    "\n",
    "    if df['date'].dtype == pl.Date:\n",
    "        df = df.with_columns(pl.col('date').cast(pl.String))\n",
    "\n",
    "    print(f\"Processing {len(df)} documents...\")\n",
    "\n",
    "    # Initialize components\n",
    "    llm = GeminiLLM(\n",
    "        model_name=config['llm_config']['model_name'],\n",
    "        google_api_key=gemini_api_key,\n",
    "        model_params=config['llm_config']['model_params']\n",
    "    )\n",
    "\n",
    "    embedder = SentenceTransformerEmbeddings(model=config['embedder_config']['model_name'])\n",
    "\n",
    "    all_results = []\n",
    "    # Build knowledge graph\n",
    "    with neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password)) as driver:\n",
    "\n",
    "        # Initialize entity resolver\n",
    "        resolver = SpaCySemanticMatchResolver(\n",
    "            driver,\n",
    "            filter_query=None,\n",
    "            resolve_properties=[\"name\"],\n",
    "            similarity_threshold=0.95,\n",
    "            spacy_model=\"en_core_web_lg\"\n",
    "        )\n",
    "\n",
    "        # Initialize KG pipeline\n",
    "        kg_pipeline = CustomKGPipeline(\n",
    "            llm=llm,\n",
    "            driver=driver,\n",
    "            embedder=embedder,\n",
    "            schema_config=config['schema_config'],\n",
    "            prompt_template=config['prompt_template_config']['template'] if not config['prompt_template_config'].get('use_default', True) else None,\n",
    "            text_splitter_config=config['text_splitter_config'],\n",
    "            resolver=resolver,\n",
    "            examples_config=None,\n",
    "            on_error='RAISE',\n",
    "            batch_size=1000,\n",
    "            max_concurrency=5\n",
    "        )\n",
    "\n",
    "        # Define document metadata mapping\n",
    "        metadata_mapping = {\n",
    "            'date': 'date',\n",
    "            'url': 'decoded_url',\n",
    "            'source': 'source'\n",
    "        }\n",
    "        \n",
    "        \n",
    "        # Process the First dataframe - MAKE A LOOP OUT OF THIS\n",
    "        print(\"Processing the first dataframe...\")\n",
    "        results_df1 = await build_kg_from_df(\n",
    "            kg_pipeline=kg_pipeline,\n",
    "            df=df,\n",
    "            document_base_field='id',\n",
    "            text_column='full_text',\n",
    "            document_metadata_mapping=metadata_mapping,\n",
    "            document_id_column=None  # Use default document ID generation\n",
    "        )\n",
    "        all_results.extend(results_df1)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Execute pipeline\n",
    "print(\"🚀 Starting Knowledge Graph construction...\")\n",
    "all_results = await build_knowledge_graph()\n",
    "print(f\"✅ Processed {len(all_results)} documents successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67cb35f",
   "metadata": {},
   "source": [
    "# Entity Resolution Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOC is available.\n",
      "Found 206 entities to process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb0f13c7bbd497a8a737586e59c8200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing similarity scores:   0%|          | 0/20805 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BufferError",
     "evalue": "Existing exports of data: object cannot be re-sized",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 92\u001b[39m, in \u001b[36mfind_similar_entities\u001b[39m\u001b[34m(threshold)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m tqdm.tqdm(similar_pairs, desc=\u001b[33m\"\u001b[39m\u001b[33mComputing similarity scores\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m         \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m similar_pairs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:328\u001b[39m, in \u001b[36mSession.run\u001b[39m\u001b[34m(self, query, parameters, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m parameters = \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_result\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpersonated_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_access_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbookmarks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnotifications_min_severity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnotifications_disabled_classifications\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._auto_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:236\u001b[39m, in \u001b[36mResult._run\u001b[39m\u001b[34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m._connection.send_all()\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:430\u001b[39m, in \u001b[36mResult._attach\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:184\u001b[39m, in \u001b[36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:861\u001b[39m, in \u001b[36mBolt.fetch_message\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m tag, fields = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhydration_hooks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhydration_hooks\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    864\u001b[39m res = \u001b[38;5;28mself\u001b[39m._process_message(tag, fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:77\u001b[39m, in \u001b[36mInbox.pop\u001b[39m\u001b[34m(self, hydration_hooks)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, hydration_hooks):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer_one_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:54\u001b[39m, in \u001b[36mInbox._buffer_one_chunk\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m chunk_size == \u001b[32m0\u001b[39m:\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Determine the chunk size and skip noop\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[43mreceive_into_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_socket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     chunk_size = \u001b[38;5;28mself\u001b[39m._buffer.pop_u16()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:345\u001b[39m, in \u001b[36mreceive_into_buffer\u001b[39m\u001b[34m(sock, buffer, n_bytes)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m buffer.used < end:\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     n = \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mview\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mused\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mused\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:364\u001b[39m, in \u001b[36mBoltSocketBase.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrecv_into\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer, nbytes):\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_io\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:339\u001b[39m, in \u001b[36mBoltSocketBase._wait_for_io\u001b[39m\u001b[34m(self, func, *args, **kwargs)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._deadline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._socket.gettimeout()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mBufferError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:222\u001b[39m, in \u001b[36mSession.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28mself\u001b[39m._connection.send_all()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[38;5;66;03m# TODO: Investigate potential non graceful close states\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:879\u001b[39m, in \u001b[36mBolt.fetch_all\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.complete:\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     detail_delta, summary_delta = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     detail_count += detail_delta\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:861\u001b[39m, in \u001b[36mBolt.fetch_message\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m tag, fields = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhydration_hooks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhydration_hooks\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    864\u001b[39m res = \u001b[38;5;28mself\u001b[39m._process_message(tag, fields)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:77\u001b[39m, in \u001b[36mInbox.pop\u001b[39m\u001b[34m(self, hydration_hooks)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, hydration_hooks):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer_one_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:59\u001b[39m, in \u001b[36mInbox._buffer_one_chunk\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33m[#\u001b[39m\u001b[38;5;132;01m%04X\u001b[39;00m\u001b[33m]  S: <NOOP>\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._local_port)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mreceive_into_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_socket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m     61\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m chunk_size = \u001b[38;5;28mself\u001b[39m._buffer.pop_u16()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:342\u001b[39m, in \u001b[36mreceive_into_buffer\u001b[39m\u001b[34m(sock, buffer, n_bytes)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end > \u001b[38;5;28mlen\u001b[39m(buffer.data):\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[43mbuffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbytearray\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(buffer.data) \u001b[38;5;28;01mas\u001b[39;00m view:\n",
      "\u001b[31mBufferError\u001b[39m: Existing exports of data: object cannot be re-sized",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mBufferError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# === MAIN EXECUTION ===\u001b[39;00m\n\u001b[32m    107\u001b[39m check_apoc()\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m pairs = \u001b[43mfind_similar_entities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m pairs = \u001b[38;5;28msorted\u001b[39m(pairs, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m], reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    110\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pairs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m similar entity pairs.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mfind_similar_entities\u001b[39m\u001b[34m(threshold)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Create SAME_AS relationships\u001b[39;00m\n\u001b[32m     85\u001b[39m query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[33mMATCH (a), (b)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[33mWHERE elementId(a) = $id1 AND elementId(b) = $id2\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[33mMERGE (a)-[:SAME_AS \u001b[39m\u001b[33m{\u001b[39m\u001b[33msimilarity: $similarity}]->(b)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilar_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mComputing similarity scores\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:130\u001b[39m, in \u001b[36mSession.__exit__\u001b[39m\u001b[34m(self, exception_type, exception_value, traceback)\u001b[39m\n\u001b[32m    128\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mself\u001b[39m._state_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:233\u001b[39m, in \u001b[36mSession.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    232\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_disconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m._state_failed = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m._closed = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:145\u001b[39m, in \u001b[36mSession._disconnect\u001b[39m\u001b[34m(self, sync)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_disconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, sync=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_disconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msync\u001b[49m\u001b[43m=\u001b[49m\u001b[43msync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n\u001b[32m    147\u001b[39m         \u001b[38;5;28mself\u001b[39m._handle_cancellation(message=\u001b[33m\"\u001b[39m\u001b[33m_disconnect\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:298\u001b[39m, in \u001b[36mWorkspace._disconnect\u001b[39m\u001b[34m(self, sync)\u001b[39m\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection:\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelease\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m     \u001b[38;5;28mself\u001b[39m._connection = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    300\u001b[39m \u001b[38;5;28mself\u001b[39m._connection_access_mode = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:481\u001b[39m, in \u001b[36mIOPool.release\u001b[39m\u001b[34m(self, *connections)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    476\u001b[39m     log.debug(\n\u001b[32m    477\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m[#\u001b[39m\u001b[38;5;132;01m%04X\u001b[39;00m\u001b[33m]  _: <POOL> release unclean connection \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    478\u001b[39m         connection.local_port,\n\u001b[32m    479\u001b[39m         connection.connection_id,\n\u001b[32m    480\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, DriverError, BoltError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    483\u001b[39m     log.debug(\n\u001b[32m    484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m[#\u001b[39m\u001b[38;5;132;01m%04X\u001b[39;00m\u001b[33m]  _: <POOL> failed to reset connection \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    485\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mon release: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    486\u001b[39m         connection.local_port,\n\u001b[32m    487\u001b[39m         exc,\n\u001b[32m    488\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:447\u001b[39m, in \u001b[36mBolt5x0.reset\u001b[39m\u001b[34m(self, dehydration_hooks, hydration_hooks)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m._append(\n\u001b[32m    444\u001b[39m     \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\x0f\u001b[39;00m\u001b[33m\"\u001b[39m, response=response, dehydration_hooks=dehydration_hooks\n\u001b[32m    445\u001b[39m )\n\u001b[32m    446\u001b[39m \u001b[38;5;28mself\u001b[39m.send_all()\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfetch_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:879\u001b[39m, in \u001b[36mBolt.fetch_all\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    877\u001b[39m response = \u001b[38;5;28mself\u001b[39m.responses[\u001b[32m0\u001b[39m]\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.complete:\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     detail_delta, summary_delta = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     detail_count += detail_delta\n\u001b[32m    881\u001b[39m     summary_count += summary_delta\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:861\u001b[39m, in \u001b[36mBolt.fetch_message\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m tag, fields = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhydration_hooks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhydration_hooks\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    864\u001b[39m res = \u001b[38;5;28mself\u001b[39m._process_message(tag, fields)\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m.idle_since = monotonic()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:77\u001b[39m, in \u001b[36mInbox.pop\u001b[39m\u001b[34m(self, hydration_hooks)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, hydration_hooks):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer_one_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     79\u001b[39m         size, tag = \u001b[38;5;28mself\u001b[39m._unpacker.unpack_structure_header()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:59\u001b[39m, in \u001b[36mInbox._buffer_one_chunk\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunk_size == \u001b[32m0\u001b[39m:\n\u001b[32m     57\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33m[#\u001b[39m\u001b[38;5;132;01m%04X\u001b[39;00m\u001b[33m]  S: <NOOP>\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._local_port)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mreceive_into_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_socket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m     61\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m chunk_size = \u001b[38;5;28mself\u001b[39m._buffer.pop_u16()\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunk_size == \u001b[32m0\u001b[39m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# chunk_size was the end marker for the message\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\UN_Conflict_Report\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:342\u001b[39m, in \u001b[36mreceive_into_buffer\u001b[39m\u001b[34m(sock, buffer, n_bytes)\u001b[39m\n\u001b[32m    340\u001b[39m end = buffer.used + n_bytes\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end > \u001b[38;5;28mlen\u001b[39m(buffer.data):\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[43mbuffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbytearray\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(buffer.data) \u001b[38;5;28;01mas\u001b[39;00m view:\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m buffer.used < end:\n",
      "\u001b[31mBufferError\u001b[39m: Existing exports of data: object cannot be re-sized"
     ]
    }
   ],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv(\"NEO4J_URI\"),\n",
    "    auth=(\"neo4j\", os.getenv(\"NEO4J_PASSWORD\"))\n",
    ")\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "def get_embedding(text):\n",
    "    return model.encode(text).tolist()\n",
    "\n",
    "# List of relevant node labels for deduplication\n",
    "ENTITY_LABELS = [\"Event\", \"Actor\", \"Location\"]\n",
    "\n",
    "def get_all_entities():\n",
    "    query_template = \"\"\"\n",
    "    MATCH (n:{label})\n",
    "    RETURN elementId(n) AS id, n.name AS name, labels(n) AS labels, properties(n) AS properties\n",
    "    \"\"\"\n",
    "    all_entities = []\n",
    "    with driver.session() as session:\n",
    "        for label in ENTITY_LABELS:\n",
    "            result = session.run(query_template.format(label=label)).data()\n",
    "            all_entities.extend(result)\n",
    "    return all_entities\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if vec1 is None or vec2 is None or len(vec1) == 0 or len(vec2) == 0:\n",
    "        return 0  # If either vector is None or empty, return 0 similarity\n",
    "    dot = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0\n",
    "\n",
    "def find_similar_entities(threshold=0.7):\n",
    "    entities = get_all_entities()\n",
    "    print(f\"Found {len(entities)} entities to process\")\n",
    "    \n",
    "    # Compute embeddings\n",
    "    for entity in entities:\n",
    "        # Filter out \"__KGBuilder__\" from labels\n",
    "        filtered_labels = [l for l in entity['labels'] if l != \"__KGBuilder__\" and l != \"__Entity__\"]\n",
    "        if filtered_labels:  # If there are any labels left\n",
    "            entity['primary_label'] = filtered_labels[0]\n",
    "        else:\n",
    "            entity['primary_label'] = entity['labels'][0]  # Fallback if only __KGBuilder__ is present\n",
    "            \n",
    "        # Start with entity label/type and name\n",
    "        text = f\"Type: {entity['primary_label']}\\nName: {entity['name']}\\n\"\n",
    "        \n",
    "        # Rest of embedding code remains the same\n",
    "        for key, value in entity['properties'].items():\n",
    "            if key != 'embedding' and value is not None:\n",
    "                if isinstance(value, (list, dict)):\n",
    "                    formatted_value = str(value)\n",
    "                else:\n",
    "                    formatted_value = value\n",
    "                text += f\"{key}: {formatted_value}\\n\"\n",
    "        \n",
    "        entity['embedding'] = get_embedding(text)\n",
    "     \n",
    "    # Find similar pairs with the new label comparison\n",
    "    similar_pairs = []\n",
    "    total_comparisons = sum(range(len(entities)))\n",
    "    for i, e1 in enumerate(entities):\n",
    "        for j, e2 in enumerate(entities[i + 1:], i + 1):\n",
    "            # Only compare if they have the same primary label (excluding __KGBuilder__)\n",
    "            if e1['primary_label'] != e2['primary_label'] or e1['primary_label'] == \"__KGBuilder__\":\n",
    "                continue\n",
    "            \n",
    "            sim = cosine_similarity(e1['embedding'], e2['embedding'])\n",
    "            if sim > threshold:\n",
    "                similar_pairs.append({\n",
    "                    \"id1\": e1['id'],\n",
    "                    \"id2\": e2['id'],\n",
    "                    \"name1\": e1['name'],\n",
    "                    \"name2\": e2['name'],\n",
    "                    \"type1\": e1['primary_label'],\n",
    "                    \"type2\": e2['primary_label'],\n",
    "                    \"similarity\": sim\n",
    "                })\n",
    "    \n",
    "    # Create SAME_AS relationships\n",
    "    query = \"\"\"\n",
    "    MATCH (a), (b)\n",
    "    WHERE elementId(a) = $id1 AND elementId(b) = $id2\n",
    "    MERGE (a)-[:SAME_AS {similarity: $similarity}]->(b)\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        for pair in tqdm.tqdm(similar_pairs, desc=\"Computing similarity scores\"):\n",
    "            session.run(query, pair)\n",
    "    \n",
    "    return similar_pairs\n",
    "\n",
    "def check_apoc():\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            session.run(\"CALL apoc.help('create')\")\n",
    "            print(\"APOC is available.\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"APOC not available: {e}\")\n",
    "        return False\n",
    "\n",
    "# === MAIN EXECUTION ===\n",
    "check_apoc()\n",
    "pairs = find_similar_entities()\n",
    "pairs = sorted(pairs, key=lambda x: x[\"similarity\"], reverse=True)\n",
    "print(f\"Found {len(pairs)} similar entity pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4205df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_similar_nodes():\n",
    "    merge_query = \"\"\"\n",
    "    // Process one pair of nodes at a time to avoid conflicts\n",
    "    MATCH (n1)-[r:SAME_AS]->(n2)\n",
    "    WHERE n1 IS NOT NULL AND n2 IS NOT NULL\n",
    "    \n",
    "    // Copy properties from n2 to n1 if they don't exist in n1\n",
    "    WITH n1, n2, [key IN keys(n2) WHERE NOT key IN keys(n1)] AS newKeys\n",
    "    FOREACH (key IN newKeys | SET n1[key] = n2[key])\n",
    "    \n",
    "    // Get all outgoing relationships from n2 (except SAME_AS)\n",
    "    WITH n1, n2\n",
    "    OPTIONAL MATCH (n2)-[outRel]->(target)\n",
    "    WHERE target IS NOT NULL AND type(outRel) <> 'SAME_AS'\n",
    "    \n",
    "    // Create equivalent relationships from n1 if they don't already exist\n",
    "    WITH n1, n2, outRel, target, type(outRel) AS relType\n",
    "    WHERE NOT EXISTS((n1)-[:`${relType}`]->(target))\n",
    "    \n",
    "    // Create new relationship with the same properties\n",
    "    FOREACH (_ IN CASE WHEN outRel IS NOT NULL THEN [1] ELSE [] END |\n",
    "        CREATE (n1)-[newRel:`${relType}`]->(target)\n",
    "        SET newRel = properties(outRel)\n",
    "    )\n",
    "    \n",
    "    // Return the node pair for the next phase\n",
    "    WITH DISTINCT n1, n2\n",
    "    \n",
    "    // Handle incoming relationships\n",
    "    OPTIONAL MATCH (source)-[inRel]->(n2)\n",
    "    WHERE source IS NOT NULL AND source <> n1 AND type(inRel) <> 'SAME_AS'\n",
    "    \n",
    "    // Create equivalent relationships to n1 if they don't already exist\n",
    "    WITH n1, n2, inRel, source, type(inRel) AS relType\n",
    "    WHERE NOT EXISTS((source)-[:`${relType}`]->(n1))\n",
    "    \n",
    "    // Create new relationship with the same properties\n",
    "    FOREACH (_ IN CASE WHEN inRel IS NOT NULL THEN [1] ELSE [] END |\n",
    "        CREATE (source)-[newRel:`${relType}`]->(n1)\n",
    "        SET newRel = properties(inRel)\n",
    "    )\n",
    "    \n",
    "    // Return distinct pairs for deletion phase\n",
    "    WITH DISTINCT n1, n2\n",
    "    \n",
    "    // Delete the second node and all its relationships\n",
    "    DETACH DELETE n2\n",
    "    \n",
    "    RETURN count(n2) AS mergedCount\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(merge_query)\n",
    "            record = result.single()\n",
    "            return record[\"mergedCount\"] if record else 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error during node merging: {e}\")\n",
    "        return 0\n",
    "\n",
    "merged = merge_similar_nodes()\n",
    "print(f\"Merged {merged} nodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c57305",
   "metadata": {},
   "source": [
    "### Node similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_similarity_query = \"\"\"\n",
    "CALL gds.nodeSimilarity.stream('amazonGraph')\n",
    "YIELD node1, node2, similarity as node_similarity\n",
    "WHERE 'Company' IN labels(gds.util.asNode(node1)) AND 'Company' IN labels(gds.util.asNode(node2))\n",
    "AND node_similarity < 1\n",
    "RETURN gds.util.asNode(node1).name AS Company1, gds.util.asNode(node2).name AS Company2, node_similarity\n",
    "ORDER BY node_similarity DESCENDING, Company1, Company2\n",
    "\"\"\"\n",
    "\n",
    "def results_to_df(query: str) -> pd.DataFrame:\n",
    "    results = gds.execute_query(query)[0]\n",
    "    df = pd.DataFrame(results, columns=results[0].keys())\n",
    "    return df\n",
    "\n",
    "df_node_similarity = results_to_df(node_similarity_query)\n",
    "print(df_node_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb28fec",
   "metadata": {},
   "source": [
    "### Create SAME_AS relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e661965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_same_as_relationship(df, column_name):\n",
    "    # Iterate over the DataFrame rows\n",
    "    for _, row in df.iterrows():\n",
    "        node1 = row[column_name + '1']\n",
    "        node2 = row[column_name + '2']\n",
    "\n",
    "        # Run Cypher query to create 'SAME_AS' relationship\n",
    "        score = row[\"combined_score\"]\n",
    "        if score > 0.20:\n",
    "            query = f\"MATCH (n1), (n2) WHERE n1.name = '{node1}' AND n2.name = '{node2}' CREATE (n1)-[:SAME_AS]->(n2)\"\n",
    "            gds.execute_query(query)\n",
    "\n",
    "create_same_as_relationship(selected_df, \"Company\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52dbed9",
   "metadata": {},
   "source": [
    "### Merge nodes with SAME_AS relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_query = \"\"\"\n",
    "MATCH (n1)-[r:SAME_AS]->(n2)\n",
    "WITH n1, n2, collect(r) as relsToDel\n",
    "\n",
    "FOREACH (rel IN relsToDel | DELETE rel)\n",
    "WITH collect(DISTINCT n1) + collect(DISTINCT n2) AS nodesToMerge\n",
    "\n",
    "UNWIND nodesToMerge AS node\n",
    "\n",
    "WITH collect(DISTINCT node) AS uniqueNodesToMerge\n",
    "CALL apoc.refactor.mergeNodes(uniqueNodesToMerge, {mergeRels:true}) YIELD node\n",
    "RETURN node\n",
    "\"\"\"\n",
    "\n",
    "gds.execute_query(merge_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
