{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ae0c9b",
   "metadata": {},
   "source": [
    "# 0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a8341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Neo4j and Neo4j GraphRAG imports\n",
    "import neo4j\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import requests\n",
    "import tqdm.notebook as tqdm\n",
    "import wikipedia\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from duckduckgo_search import DDGS\n",
    "from google import genai\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j_graphrag.embeddings import SentenceTransformerEmbeddings\n",
    "from neo4j_graphrag.experimental.components.resolver import (\n",
    "    FuzzyMatchResolver,\n",
    "    SinglePropertyExactMatchResolver,\n",
    "    SpaCySemanticMatchResolver,\n",
    ")\n",
    "from neo4j_graphrag_custom.kg_builder import (\n",
    "    CustomKGPipeline,\n",
    "    GeminiLLM,\n",
    "    build_kg_from_df,\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182b7fc",
   "metadata": {},
   "source": [
    "Let's first check the available Gemini models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b114e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='models/embedding-gecko-001' display_name='Embedding Gecko' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1024 output_token_limit=1 supported_actions=['embedText', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.0-pro-vision-latest' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-pro-vision' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-latest' display_name='Gemini 1.5 Pro Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-001' display_name='Gemini 1.5 Pro 001' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-002' display_name='Gemini 1.5 Pro 002' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro' display_name='Gemini 1.5 Pro' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-latest' display_name='Gemini 1.5 Flash Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-001' display_name='Gemini 1.5 Flash 001' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-001-tuning' display_name='Gemini 1.5 Flash 001 Tuning' description='Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=16384 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createTunedModel'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash' display_name='Gemini 1.5 Flash' description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-002' display_name='Gemini 1.5 Flash 002' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b' display_name='Gemini 1.5 Flash-8B' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-001' display_name='Gemini 1.5 Flash-8B 001' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-latest' display_name='Gemini 1.5 Flash-8B Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-exp-0827' display_name='Gemini 1.5 Flash 8B Experimental 0827' description='Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-exp-0924' display_name='Gemini 1.5 Flash 8B Experimental 0924' description='Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-exp-03-25' display_name='Gemini 2.5 Pro Experimental 03-25' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-03-25' display_name='Gemini 2.5 Pro Preview 03-25' description='Gemini 2.5 Pro Preview 03-25' version='2.5-preview-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-04-17' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-05-20' display_name='Gemini 2.5 Flash Preview 05-20' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-05-20' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-04-17-thinking' display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-05-06' display_name='Gemini 2.5 Pro Preview 05-06' description='Preview release (May 6th, 2025) of Gemini 2.5 Pro' version='2.5-preview-05-06' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-06-05' display_name='Gemini 2.5 Pro Preview' description='Preview release (June 5th, 2025) of Gemini 2.5 Pro' version='2.5-preview-06-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-exp' display_name='Gemini 2.0 Flash Experimental' description='Gemini 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash' display_name='Gemini 2.0 Flash' description='Gemini 2.0 Flash' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-001' display_name='Gemini 2.0 Flash 001' description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-001' display_name='Gemini 2.0 Flash-Lite 001' description='Stable version of Gemini 2.0 Flash Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite' display_name='Gemini 2.0 Flash-Lite' description='Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-preview-02-05' display_name='Gemini 2.0 Flash-Lite Preview 02-05' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-preview' display_name='Gemini 2.0 Flash-Lite Preview' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-pro-exp' display_name='Gemini 2.0 Pro Experimental' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-pro-exp-02-05' display_name='Gemini 2.0 Pro Experimental 02-05' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-exp-1206' display_name='Gemini Experimental 1206' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp-01-21' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp-1219' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-tts' display_name='Gemini 2.5 Flash Preview TTS' description='Gemini 2.5 Flash Preview TTS' version='gemini-2.5-flash-exp-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-tts' display_name='Gemini 2.5 Pro Preview TTS' description='Gemini 2.5 Pro Preview TTS' version='gemini-2.5-pro-preview-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=65536 output_token_limit=65536 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/learnlm-2.0-flash-experimental' display_name='LearnLM 2.0 Flash Experimental' description='LearnLM 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=32768 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-1b-it' display_name='Gemma 3 1B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-4b-it' display_name='Gemma 3 4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-12b-it' display_name='Gemma 3 12B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-27b-it' display_name='Gemma 3 27B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3n-e4b-it' display_name='Gemma 3n E4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/embedding-001' display_name='Embedding 001' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/text-embedding-004' display_name='Text Embedding 004' description='Obtain a distributed representation of a text.' version='004' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-embedding-exp-03-07' display_name='Gemini Embedding Experimental 03-07' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-embedding-exp' display_name='Gemini Embedding Experimental' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/aqa' display_name='Model that performs Attributed Question Answering.' description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=7168 output_token_limit=1024 supported_actions=['generateAnswer'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/imagen-3.0-generate-002' display_name='Imagen 3.0 002 model' description='Vertex served Imagen 3.0 002 model' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/veo-2.0-generate-001' display_name='Veo 2' description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-native-audio-dialog' display_name='Gemini 2.5 Flash Preview Native Audio Dialog' description='Gemini 2.5 Flash Preview Native Audio Dialog' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3' display_name='Gemini 2.5 Flash Preview Native Audio Dialog RAI v3' description='Gemini 2.5 Flash Preview Native Audio Dialog RAI v3' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-exp-native-audio-thinking-dialog' display_name='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' description='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' version='gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-live-001' display_name='Gemini 2.0 Flash 001' description='Gemini 2.0 Flash 001' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['bidiGenerateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n"
     ]
    }
   ],
   "source": [
    "load_dotenv('.env', override=True)\n",
    "\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if gemini_api_key:\n",
    "    client = genai.Client(api_key=gemini_api_key)  # Configure the API key for genai\n",
    "else:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable is not set.\")\n",
    "\n",
    "# Display available models\n",
    "for model in client.models.list():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad2805",
   "metadata": {},
   "source": [
    "We also have to make sure that the corresponding SpaCy model for text embedding used at the resolving step is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43270dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'en_core_web_lg' is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "def ensure_spacy_model(model_name):\n",
    "    if importlib.util.find_spec(model_name) is None:\n",
    "        print(f\"Model '{model_name}' not found. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", model_name])\n",
    "    else:\n",
    "        print(f\"Model '{model_name}' is already installed.\")\n",
    "\n",
    "# Use it for 'en_core_web_lg'\n",
    "ensure_spacy_model(\"en_core_web_lg\")  # Model used for resolving entities in the KG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20a0a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pass_examples': False,\n",
       " 'examples': [{'input_text': \"Text: On January 1, 2023, a significant conflict erupted in the Middle East involving multiple countries and organizations. The conflict, named 'Middle East Conflict 2023', lasted until March 15, 2023. Key actors included the 'Middle East Coalition' and the 'Opposing Forces'. The conflict resulted in a high level of destruction and instability in the region.\",\n",
       "   'schema': {'nodes': [{'id': '0',\n",
       "      'label': 'Event',\n",
       "      'properties': {'name': 'Middle East Conflict 2023',\n",
       "       'date': '2023-01-01',\n",
       "       'end_date': '2023-03-15',\n",
       "       'type': 'Conflict',\n",
       "       'severity': 5,\n",
       "       'description': 'A significant conflict in the Middle East.'}},\n",
       "     {'id': '1',\n",
       "      'label': 'Actor',\n",
       "      'properties': {'name': 'Middle East Coalition', 'type': 'Organization'}},\n",
       "     {'id': '2',\n",
       "      'label': 'Actor',\n",
       "      'properties': {'name': 'Opposing Forces', 'type': 'Organization'}},\n",
       "     {'id': '3',\n",
       "      'label': 'Region',\n",
       "      'properties': {'name': 'Middle East', 'stability': 0.2}}],\n",
       "    'relationships': [{'type': 'OCCURRED_IN',\n",
       "      'start_node_id': '0',\n",
       "      'end_node_id': '3',\n",
       "      'properties': {'start_date': None, 'end_date': None, 'certainty': 1.0}},\n",
       "     {'type': 'PARTICIPATED_IN',\n",
       "      'start_node_id': '1',\n",
       "      'end_node_id': '0',\n",
       "      'properties': {'role': None,\n",
       "       'significance': 1.0,\n",
       "       'start_date': None,\n",
       "       'end_date': None}},\n",
       "     {'type': 'PARTICIPATED_IN',\n",
       "      'start_node_id': '2',\n",
       "      'end_node_id': '0',\n",
       "      'properties': {'role': None,\n",
       "       'significance': 1.0,\n",
       "       'start_date': None,\n",
       "       'end_date': None}}]}},\n",
       "  {'input_text': 'Text: On February 14, 2023, ...',\n",
       "   'schema': {'nodes': [{'id': '0',\n",
       "      'label': 'Event',\n",
       "      'properties': {'name': 'February 14 Incident',\n",
       "       'date': '2023-02-14',\n",
       "       'end_date': None,\n",
       "       'type': 'Attack',\n",
       "       'severity': 4,\n",
       "       'description': 'An attack occurred on February 14.'}}]}}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('kg_building_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config['examples_config']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39afcd",
   "metadata": {},
   "source": [
    "# 1. Loading the data\n",
    "\n",
    "The data is loaded here as a reference, but it is loaded again inside the pipeline below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4320d1",
   "metadata": {},
   "source": [
    "## 1.2. Factal sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29a4e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>Published date</th><th>Severity</th><th>Published text</th><th>Translated text</th><th>Original language</th><th>Source URL</th><th>Status</th><th>Country</th></tr><tr><td>u32</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;2025-06-03 15:28:28.271179+00:…</td><td>3</td><td>&quot;WFP and UNICEF now say five me…</td><td>null</td><td>null</td><td>&quot;https://www.unicef.org/press-r…</td><td>&quot;published&quot;</td><td>&quot;Sudan&quot;</td></tr><tr><td>2</td><td>&quot;2025-06-03 10:10:04.994458+00:…</td><td>3</td><td>&quot;&quot;Multiple casualties&quot; after WF…</td><td>null</td><td>null</td><td>&quot;https://www.reuters.com/world/…</td><td>&quot;published&quot;</td><td>&quot;Sudan&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "┌─────┬──────────────┬──────────┬──────────────┬───┬──────────┬──────────────┬───────────┬─────────┐\n",
       "│ id  ┆ Published    ┆ Severity ┆ Published    ┆ … ┆ Original ┆ Source URL   ┆ Status    ┆ Country │\n",
       "│ --- ┆ date         ┆ ---      ┆ text         ┆   ┆ language ┆ ---          ┆ ---       ┆ ---     │\n",
       "│ u32 ┆ ---          ┆ i64      ┆ ---          ┆   ┆ ---      ┆ str          ┆ str       ┆ str     │\n",
       "│     ┆ str          ┆          ┆ str          ┆   ┆ str      ┆              ┆           ┆         │\n",
       "╞═════╪══════════════╪══════════╪══════════════╪═══╪══════════╪══════════════╪═══════════╪═════════╡\n",
       "│ 1   ┆ 2025-06-03   ┆ 3        ┆ WFP and      ┆ … ┆ null     ┆ https://www. ┆ published ┆ Sudan   │\n",
       "│     ┆ 15:28:28.271 ┆          ┆ UNICEF now   ┆   ┆          ┆ unicef.org/p ┆           ┆         │\n",
       "│     ┆ 179+00:…     ┆          ┆ say five me… ┆   ┆          ┆ ress-r…      ┆           ┆         │\n",
       "│ 2   ┆ 2025-06-03   ┆ 3        ┆ \"Multiple    ┆ … ┆ null     ┆ https://www. ┆ published ┆ Sudan   │\n",
       "│     ┆ 10:10:04.994 ┆          ┆ casualties\"  ┆   ┆          ┆ reuters.com/ ┆           ┆         │\n",
       "│     ┆ 458+00:…     ┆          ┆ after WF…    ┆   ┆          ┆ world/…      ┆           ┆         │\n",
       "└─────┴──────────────┴──────────┴──────────────┴───┴──────────┴──────────────┴───────────┴─────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global df\n",
    "df = pl.read_csv('factal_single_topic_report-2025-05-01-2025-06-05.csv')\n",
    "\n",
    "# Create an index for each row\n",
    "df = df.with_row_index(name=\"id\", offset=1)\n",
    "# Rename \"Associated topics\" column to \"Country\"\n",
    "df = df.rename({\"Associated topics\": \"Country\"})\n",
    "\n",
    "df=df.head(20)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c640450",
   "metadata": {},
   "source": [
    "### Load Admin1 locations from HDX database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7cbcb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Admin Level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "P-Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Parent P-Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Valid from date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "72bb4df5-1803-46b0-92e0-25c068bf1538",
       "rows": [
        [
         "0",
         "1",
         "SDN",
         "1",
         "SD01",
         "Khartoum",
         "SDN",
         "2020-08-31",
         "Sudan"
        ],
        [
         "1",
         "2",
         "SDN",
         "1",
         "SD02",
         "North Darfur",
         "SDN",
         "2020-08-31",
         "Sudan"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Location</th>\n",
       "      <th>Admin Level</th>\n",
       "      <th>P-Code</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parent P-Code</th>\n",
       "      <th>Valid from date</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SDN</td>\n",
       "      <td>1</td>\n",
       "      <td>SD01</td>\n",
       "      <td>Khartoum</td>\n",
       "      <td>SDN</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>Sudan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SDN</td>\n",
       "      <td>1</td>\n",
       "      <td>SD02</td>\n",
       "      <td>North Darfur</td>\n",
       "      <td>SDN</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>Sudan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Location Admin Level P-Code          Name Parent P-Code Valid from date  \\\n",
       "0   1      SDN           1   SD01      Khartoum           SDN      2020-08-31   \n",
       "1   2      SDN           1   SD02  North Darfur           SDN      2020-08-31   \n",
       "\n",
       "  Country  \n",
       "0   Sudan  \n",
       "1   Sudan  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global df2\n",
    "admin1 = pd.read_csv(r\"C:\\Users\\matia\\Downloads\\global_pcodes_adm_1_2.csv\")\n",
    "df2 = admin1[admin1['Location'] == 'SDN'].copy()\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df2 = df2.reset_index(names='id')\n",
    "df2['id'] = df2['id'] + 1\n",
    "df2['Country'] = 'Sudan'\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646aee4",
   "metadata": {},
   "source": [
    "# 2. Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9bfa627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph that will be used for creating security reports for different countries.\n",
      "\n",
      "Extract the entities (nodes) and specify their type from the following Input text.\n",
      "Also extract the relationships between these nodes. The relationship direction goes from the start node to the end node.\n",
      "\n",
      "Output ONLY valid JSON with this exact structure without any commentary, explanation, or markdown formatting:\n",
      "{{\"nodes\": [ {{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {{\"name\": \"name of entity\" }} }}],\n",
      "\"relationships\": [{{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"details\": \"Description of the relationship\"}} }}] }}\n",
      "\n",
      "- Use only the information from the Input text. Do not add any additional information.\n",
      "- If the input text is empty, return empty Json.\n",
      "- Make sure to create as many nodes and relationships as needed to offer rich context for generating a security-related knowledge graph.\n",
      "- An AI knowledge assistant must be able to read this graph and immediately understand the context to inform detailed research questions.\n",
      "- Multiple documents will be ingested from different sources and we are using this property graph to connect information, so make sure entity types are fairly general.\n",
      "- Do not create edges between nodes and chunks when the relationship is not clear enough.\n",
      "\n",
      "Use only the following nodes and relationships (if provided):\n",
      "{schema}\n",
      "\n",
      "Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
      "Do respect the source and target node types for relationship and the relationship direction.\n",
      "\n",
      "Do not return any additional information other than the JSON in it.\n",
      "\n",
      "Examples:\n",
      "{examples}\n",
      "\n",
      "Input text:\n",
      "{text}\n"
     ]
    }
   ],
   "source": [
    "# Open configuration file\n",
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, 'kg_building_config.json')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "prompt_template=config['prompt_template_config']['template'] if config['prompt_template_config'].get('use_default') == False else None\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e872a9",
   "metadata": {},
   "source": [
    "## 2.2. With a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c023659",
   "metadata": {},
   "source": [
    "### A. Using the `SpaCySemanticMatchResolver`\n",
    "\n",
    "More useful information about the resolvers can be found in the [user guide](https://neo4j.com/docs/neo4j-graphrag-python/current/user_guide_kg_builder.html#entity-resolver). Below, we use different resolvers (from the most aggressive - spaCy to the most conservative - exact matching) to get a broad overview of the performance results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2a91f2",
   "metadata": {},
   "source": [
    "#### With Factal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage code\n",
    "async def main():\n",
    "\n",
    "    # Load configuration and setup\n",
    "\n",
    "    script_dir = os.getcwd()\n",
    "\n",
    "    # script_dir = os.path.dirname(os.path.abspath(__file__))  # Uncomment if running as a script\n",
    "\n",
    "    # Load environment variables from a .env file\n",
    "    dotenv_path = os.path.join(script_dir, '.env')\n",
    "    load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "    # Open configuration file from JSON format\n",
    "    config_path = os.path.join(script_dir, 'kg_building_config.json')\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "    \n",
    "    # Neo4j connection\n",
    "    neo4j_uri = os.getenv('NEO4J_URI')\n",
    "    neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "    neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "    \n",
    "    # Check if gemini_api_key is set\n",
    "    if gemini_api_key:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Gemini API key is not set. Please provide a valid API key.\")\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = GeminiLLM(\n",
    "        model_name=config['llm_config']['model_name'],\n",
    "        google_api_key=gemini_api_key,\n",
    "        model_params=config['llm_config']['model_params']\n",
    "    )\n",
    "    \n",
    "    # Initialize embedder\n",
    "    embedder = SentenceTransformerEmbeddings(model=config['embedder_config']['model_name'])\n",
    "    \n",
    "    # Configure text splitter\n",
    "    text_splitter_config = config['text_splitter_config']\n",
    "    \n",
    "    # Load data \n",
    "    #df_path = os.path.join(script_dir, 'factal_single_topic_report-2025-05-01-2025-06-05.csv')\n",
    "    #df = pl.read_csv(    df = df.with_row_index(name=\"id\", offset=1)\n",
    "\n",
    "    # Access the global df variable\n",
    "    global df\n",
    "    # Add row index only once\n",
    "    #df = df.with_row_index(name=\"id\", offset=1)\n",
    "\n",
    "    # Convert the \"id\" to a string to ensure it is treated as a document ID\n",
    "    df = df.with_columns(pl.col('id').cast(pl.String))\n",
    "    \n",
    "    # Create the pipeline - use with statement to ensure proper resource management\n",
    "    # and to ensure the driver is closed after use\n",
    "    with neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password)) as driver:\n",
    "        \n",
    "        # Initialize entity resolver\n",
    "        resolver = SpaCySemanticMatchResolver(  # Merge nodes with same label and similar textual properties\n",
    "            driver,\n",
    "            filter_query=None,  # \"WHERE (entity)-[:FROM_CHUNK]->(:Chunk)-[:FROM_DOCUMENT]->(doc:Document {id = 'docId'}\",  # Used to reduce the resolution scope to a specific document\n",
    "            resolve_properties=[\"name\"],  # Properties to use for resolution (default is \"name\")\n",
    "            similarity_threshold=0.8,  # The similarity threshold above which nodes are merged (default is 0.8). Higher threshold will result in less false positives, but may miss some matches. \n",
    "            spacy_model=\"en_core_web_lg\"  # spaCy model to use for resolution (default is \"en_core_web_lg\")\n",
    "        )\n",
    "\n",
    "        # Initialize the custom KG pipeline\n",
    "        kg_pipeline = CustomKGPipeline(\n",
    "            llm=llm,\n",
    "            driver=driver,\n",
    "            embedder=embedder,\n",
    "            schema_config=config['schema_config'],\n",
    "            prompt_template=config['prompt_template_config']['template'] if config['prompt_template_config'].get('use_default') == False else None,\n",
    "            text_splitter_config=text_splitter_config,\n",
    "            resolver=resolver,\n",
    "            examples_config=None,  # Use None if no examples are provided\n",
    "            on_error='RAISE',\n",
    "            batch_size=1000,\n",
    "            max_concurrency=5\n",
    "        )\n",
    "        \n",
    "        # Define metadata mapping (document properties additional to base field \n",
    "        # to dataframe columns)\n",
    "        metadata_mapping = {\n",
    "            \"source\": \"Source URL\",\n",
    "            \"published_date\": \"Published date\"\n",
    "        }\n",
    "        \n",
    "        # Process the dataframe\n",
    "        results = await build_kg_from_df(\n",
    "            kg_pipeline=kg_pipeline,\n",
    "            df=df,\n",
    "            document_base_field='id',\n",
    "            text_column='Published text',\n",
    "            document_metadata_mapping=metadata_mapping,\n",
    "            document_id_column=None  # Use default document ID generation\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Asyncio event loop to run the main function in a Jupyter notebook\n",
    "results = await main()\n",
    "print(f\"Processed {len(results)} documents\")\n",
    "\n",
    "# # Asyncio event loop to run the main function in a script\n",
    "# if __name__ == \"__main__\":\n",
    "#     results = asyncio.run(main())\n",
    "#     print(f\"Processed {len(results)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12dbf8f",
   "metadata": {},
   "source": [
    "# NASTIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a7e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing first DataFrame...\n",
      "Processing row 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM response is not valid JSON for chunk_index=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: run_id='a566a80a-3644-4348-9d69-39279e8f59e7' result={'resolver': {'number_of_nodes_to_resolve': 0, 'number_of_created_nodes': 0}}\n",
      "Elapsed time: 9.59 seconds\n",
      "Estimated time remaining: 182.24 seconds\n",
      "\n",
      "Processing row 2 of 20\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    global df, df2 \n",
    "\n",
    "    # Load configuration and setup\n",
    "    script_dir = os.getcwd()\n",
    "\n",
    "    # Load environment variables from a .env file\n",
    "    dotenv_path = os.path.join(script_dir, '.env')\n",
    "    load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "    # Open configuration file from JSON format\n",
    "    config_path = os.path.join(script_dir, 'kg_building_config.json')\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "\n",
    "    # Neo4j connection\n",
    "    neo4j_uri = os.getenv('NEO4J_URI')\n",
    "    neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "    neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "    # Check if gemini_api_key is set\n",
    "    if gemini_api_key:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Gemini API key is not set. Please provide a valid API key.\")\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = GeminiLLM(\n",
    "        model_name=config['llm_config']['model_name'],\n",
    "        google_api_key=gemini_api_key,\n",
    "        model_params=config['llm_config']['model_params']\n",
    "    )\n",
    "\n",
    "    # Initialize embedder\n",
    "    embedder = SentenceTransformerEmbeddings(model=config['embedder_config']['model_name'])\n",
    "\n",
    "    # Configure text splitter\n",
    "    text_splitter_config = config['text_splitter_config']\n",
    "\n",
    "    # Define metadata mapping (document properties additional to base field\n",
    "    # to dataframe columns)\n",
    "    metadata_mapping = {\n",
    "        \"source\": \"Source URL\",\n",
    "        \"published_date\": \"Published date\",\n",
    "        \"country\": \"Country\"\n",
    "    }\n",
    "\n",
    "    # Factal DF\n",
    "    global df\n",
    "    df = df.with_columns(pl.col('id').cast(pl.String))\n",
    "\n",
    "    # Admin1 DF\n",
    "    global df2\n",
    "\n",
    "    # Create the pipeline - use with statement to ensure proper resource management\n",
    "    # and to ensure the driver is closed after use\n",
    "    all_results = []\n",
    "    with neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password)) as driver:\n",
    "\n",
    "        # Initialize entity resolver\n",
    "        resolver = SpaCySemanticMatchResolver(\n",
    "            driver,\n",
    "            filter_query=None,\n",
    "            resolve_properties=[\"name\"],\n",
    "            similarity_threshold=0.8,\n",
    "            spacy_model=\"en_core_web_lg\"\n",
    "        )\n",
    "\n",
    "        # Initialize the custom KG pipeline (this needs to be done only once)\n",
    "        kg_pipeline = CustomKGPipeline(\n",
    "            llm=llm,\n",
    "            driver=driver,\n",
    "            embedder=embedder,\n",
    "            schema_config=config['schema_config'],\n",
    "            prompt_template=config['prompt_template_config']['template'] if config['prompt_template_config'].get('use_default') == False else None,\n",
    "            text_splitter_config=text_splitter_config,\n",
    "            resolver=resolver,\n",
    "            examples_config=None,\n",
    "            on_error='RAISE',\n",
    "            batch_size=1000,\n",
    "            max_concurrency=5\n",
    "        )\n",
    "\n",
    "        # --- Process the first dataframe ---\n",
    "        print(\"\\nProcessing first DataFrame...\")\n",
    "        results_df1 = await build_kg_from_df(\n",
    "            kg_pipeline=kg_pipeline,\n",
    "            df=df,\n",
    "            document_base_field='id',\n",
    "            text_column='Published text',\n",
    "            document_metadata_mapping=metadata_mapping,\n",
    "            document_id_column=None\n",
    "        )\n",
    "        all_results.extend(results_df1)\n",
    "        print(f\"Finished processing first DataFrame. Total documents processed: {len(all_results)}\")\n",
    "\n",
    "        # --- Process the second dataframe (if loaded successfully) ---\n",
    "        if df2 is not None and not df2.is_empty():\n",
    "            print(\"\\nProcessing second DataFrame...\")\n",
    "            results_df2 = await build_kg_from_df(\n",
    "                kg_pipeline=kg_pipeline,\n",
    "                df=df2, # Pass the second DataFrame here\n",
    "                document_base_field='id',\n",
    "                text_column='Name', # Make sure this column name exists in df2\n",
    "                document_metadata_mapping=metadata_mapping, # Reuse mapping or define a new one if df2 has different metadata\n",
    "                document_id_column=None\n",
    "            )\n",
    "            all_results.extend(results_df2)\n",
    "            print(f\"Finished processing second DataFrame. Total documents processed: {len(all_results)}\")\n",
    "        else:\n",
    "            print(\"Second DataFrame was not processed (either not loaded or empty).\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# Asyncio event loop to run the main function in a Jupyter notebook\n",
    "results = await main()\n",
    "print(f\"Processed {len(results)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a43883",
   "metadata": {},
   "source": [
    "### B. Using the `FuzzyMatchResolver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64381b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage code\n",
    "async def main():\n",
    "\n",
    "    # Load configuration and setup\n",
    "    script_dir = os.getcwd()\n",
    "\n",
    "    # Load environment variables from a .env file\n",
    "    dotenv_path = os.path.join(script_dir, '.env')\n",
    "    load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "    # Open configuration file from JSON format\n",
    "    config_path = os.path.join(script_dir, 'kg_building_config.json')\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "    \n",
    "    # Neo4j connection\n",
    "    neo4j_uri = os.getenv('NEO4J_URI')\n",
    "    neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "    neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "    \n",
    "    # Check if gemini_api_key is set\n",
    "    if gemini_api_key:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Gemini API key is not set. Please provide a valid API key.\")\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = GeminiLLM(\n",
    "        model_name=config['llm_config']['model_name'],\n",
    "        google_api_key=gemini_api_key,\n",
    "        model_params=config['llm_config']['model_params']\n",
    "    )\n",
    "    \n",
    "    # Initialize embedder\n",
    "    embedder = SentenceTransformerEmbeddings(model=config['embedder_config']['model_name'])\n",
    "    \n",
    "    # Configure text splitter\n",
    "    text_splitter_config = config['text_splitter_config']\n",
    "    \n",
    "    # Use the global dataframe instead of trying to load the non-existent parquet file\n",
    "    global df\n",
    "    \n",
    "    # Convert the \"id\" to a string to ensure it is treated as a document ID\n",
    "    df = df.with_columns(pl.col('id').cast(pl.String))\n",
    "    \n",
    "    # Create the pipeline\n",
    "    with neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password)) as driver:\n",
    "        \n",
    "        # Initialize entity resolver\n",
    "        resolver = FuzzyMatchResolver(  # Merge nodes with same label and similar textual properties\n",
    "            driver,\n",
    "            filter_query=None,\n",
    "            resolve_properties=[\"name\"],\n",
    "            similarity_threshold=0.8,\n",
    "        )\n",
    "\n",
    "        # Initialize the custom KG pipeline\n",
    "        kg_pipeline = CustomKGPipeline(\n",
    "            llm=llm,\n",
    "            driver=driver,\n",
    "            embedder=embedder,\n",
    "            schema_config=config['schema_config'],\n",
    "            prompt_template=config['prompt_template_config']['template'] if config['prompt_template_config'].get('use_default') == False else None,\n",
    "            text_splitter_config=text_splitter_config,\n",
    "            resolver=resolver,\n",
    "            examples_config=None,\n",
    "            on_error='RAISE',\n",
    "            batch_size=1000,\n",
    "            max_concurrency=5\n",
    "        )\n",
    "        \n",
    "        # Define metadata mapping - adjust to match your factal CSV columns\n",
    "        metadata_mapping = {\n",
    "            \"source\": \"Source URL\",\n",
    "            \"published_date\": \"Published date\"\n",
    "        }\n",
    "        \n",
    "        # Process the dataframe - use column names from your factal CSV\n",
    "        results = await build_kg_from_df(\n",
    "            kg_pipeline=kg_pipeline,\n",
    "            df=df,\n",
    "            document_base_field='id',\n",
    "            text_column='Published text', \n",
    "            document_metadata_mapping=metadata_mapping,\n",
    "            document_id_column=None\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Asyncio event loop to run the main function\n",
    "results = await main()\n",
    "print(f\"Processed {len(results)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1d9f9",
   "metadata": {},
   "source": [
    "### C. Using the `SinglePropertyExactMatchResolver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ccda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage code\n",
    "async def main():\n",
    "\n",
    "    # Load configuration and setup\n",
    "\n",
    "    script_dir = os.getcwd()\n",
    "\n",
    "    # script_dir = os.path.dirname(os.path.abspath(__file__))  # Uncomment if running as a script\n",
    "\n",
    "    # Load environment variables from a .env file\n",
    "    dotenv_path = os.path.join(script_dir, '.env')\n",
    "    load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "    # Open configuration file from JSON format\n",
    "    config_path = os.path.join(script_dir, 'kg_building_config.json')\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "    \n",
    "    # Neo4j connection\n",
    "    neo4j_uri = os.getenv('NEO4J_URI')\n",
    "    neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "    neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "    \n",
    "    # Check if gemini_api_key is set\n",
    "    if gemini_api_key:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Gemini API key is not set. Please provide a valid API key.\")\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = GeminiLLM(\n",
    "        model_name=config['llm_config']['model_name'],\n",
    "        google_api_key=gemini_api_key,\n",
    "        model_params=config['llm_config']['model_params']\n",
    "    )\n",
    "    \n",
    "    # Initialize embedder\n",
    "    embedder = SentenceTransformerEmbeddings(model=config['embedder_config']['model_name'])\n",
    "    \n",
    "    # Configure text splitter\n",
    "    text_splitter_config = config['text_splitter_config']\n",
    "    \n",
    "    # Load data\n",
    "    df_path = os.path.join(script_dir, 'FILTERED_DATAFRAME.parquet')\n",
    "    df = pl.read_parquet(df_path)\n",
    "\n",
    "    # Convert 'date' column to string format (from YYYYMMDD to YYYY-MM-DD)\n",
    "    df = df.with_columns(pl.col('date').cast(pl.String))\n",
    "    df = df.with_columns(pl.col('date').str.strptime(pl.Date, format='%Y%m%d'))\n",
    "    df = df.with_columns(pl.col('date').dt.strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Create subset of the dataframe for testing\n",
    "    df = df.head(10)\n",
    "    \n",
    "    # Create the pipeline - use with statement to ensure proper resource management\n",
    "    # and to ensure the driver is closed after use\n",
    "    with neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password)) as driver:\n",
    "        \n",
    "        # Initialize entity resolver\n",
    "        resolver = SinglePropertyExactMatchResolver(  # Merge nodes with same label and exact property\n",
    "            driver,\n",
    "            filter_query=None,  # \"WHERE (entity)-[:FROM_CHUNK]->(:Chunk)-[:FROM_DOCUMENT]->(doc:Document {id = 'docId'}\",  # Used to reduce the resolution scope to a specific document\n",
    "            resolve_property=\"name\"  # Property to use for resolution (default is \"name\")\n",
    "        )\n",
    "\n",
    "        # Initialize the custom KG pipeline\n",
    "        kg_pipeline = CustomKGPipeline(\n",
    "            llm=llm,\n",
    "            driver=driver,\n",
    "            embedder=embedder,\n",
    "            schema_config=config['schema_config'],\n",
    "            prompt_template=config['prompt_template_config']['template'] if config['prompt_template_config'].get('use_default') == False else None,\n",
    "            text_splitter_config=text_splitter_config,\n",
    "            resolver=resolver,\n",
    "            examples_config=None,\n",
    "            on_error='RAISE',\n",
    "            batch_size=1000,\n",
    "            max_concurrency=5,\n",
    "        )\n",
    "        \n",
    "        # Define metadata mapping (document properties additional to base field \n",
    "        # to dataframe columns)\n",
    "        metadata_mapping = {\n",
    "            \"source\": \"url\",\n",
    "            \"published_date\": \"date\"\n",
    "        }\n",
    "        \n",
    "        # Process the dataframe\n",
    "        results = await build_kg_from_df(\n",
    "            kg_pipeline=kg_pipeline,\n",
    "            df=df,\n",
    "            document_base_field='title',\n",
    "            text_column='full_text',\n",
    "            document_metadata_mapping=metadata_mapping,\n",
    "            document_id_column=None  # Use default document ID generation\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Asyncio event loop to run the main function in a Jupyter notebook\n",
    "results = await main()\n",
    "print(f\"Processed {len(results)} documents\")\n",
    "\n",
    "# # Asyncio event loop to run the main function in a script\n",
    "# if __name__ == \"__main__\":\n",
    "#     results = asyncio.run(main())\n",
    "#     print(f\"Processed {len(results)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c55af5",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "- The **spaCy** resolver is the one which yields the smallest graph, and the one which resolves the most nodes among the default resolvers. However, it seems to be the slowest resolver.\n",
    "- The `FuzzyMatchResolver` does not seem to work very well out of the box, as the number of duplicate nodes and edges increases significantly.\n",
    "- Finally, the `SinglePropertyExactMatchResolver` produces the largest graph among the 3 resolvers, but prunes a relatively decent amount of nodes and edges when running the instance twice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb37f9e",
   "metadata": {},
   "source": [
    "### Ex-post resolver\n",
    "\n",
    "Note that it is also possible to run a resolver ex-post, after the graph has been created (see the [user guide for the resolvers](https://neo4j.com/docs/neo4j-graphrag-python/current/user_guide_kg_builder.html#entity-resolver)) and outside the pipeline of the KG building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b940590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity resolution completed.\n",
      "number_of_nodes_to_resolve=164 number_of_created_nodes=0\n"
     ]
    }
   ],
   "source": [
    "# Neo4j connection\n",
    "neo4j_uri = os.getenv('NEO4J_URI')\n",
    "neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "with neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password)) as driver:\n",
    "        \n",
    "        # Initialize entity resolver\n",
    "        resolver = SpaCySemanticMatchResolver(  # Merge nodes with same label and similar textual properties\n",
    "            driver,\n",
    "            filter_query=None,  # \"WHERE (entity)-[:FROM_CHUNK]->(:Chunk)-[:FROM_DOCUMENT]->(doc:Document {id = 'docId'}\",  # Used to reduce the resolution scope to a specific document\n",
    "            resolve_properties=[\"name\"],  # Properties to use for resolution (default is \"name\")\n",
    "            similarity_threshold=0.8,  # The similarity threshold above which nodes are merged (default is 0.8). Higher threshold will result in less false positives, but may miss some matches. \n",
    "            spacy_model=\"en_core_web_lg\"  # spaCy model to use for resolution (default is \"en_core_web_lg\")\n",
    "        )\n",
    "\n",
    "        result = await resolver.run()\n",
    "        print(\"Entity resolution completed.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d4aba",
   "metadata": {},
   "source": [
    "## 2.3. Creating the KG without a schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de7444",
   "metadata": {},
   "source": [
    "## 2.4. Passing examples for few-shot learning\n",
    "\n",
    "Ensure that the `pass_examples` key in the JSON configuration file is set to `true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add400d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage code\n",
    "async def main():\n",
    "\n",
    "    # Load configuration and setup\n",
    "\n",
    "    script_dir = os.getcwd()\n",
    "\n",
    "    # script_dir = os.path.dirname(os.path.abspath(__file__))  # Uncomment if running as a script\n",
    "\n",
    "    # Load environment variables from a .env file\n",
    "    dotenv_path = os.path.join(script_dir, '.env')\n",
    "    load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "    # Open configuration file from JSON format\n",
    "    config_path = os.path.join(script_dir, 'kg_building_config.json')\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "    \n",
    "    # Neo4j connection\n",
    "    neo4j_uri = os.getenv('NEO4J_URI')\n",
    "    neo4j_username = os.getenv('NEO4J_USERNAME')\n",
    "    neo4j_password = os.getenv('NEO4J_PASSWORD')\n",
    "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "    \n",
    "    # Check if gemini_api_key is set\n",
    "    if gemini_api_key:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Gemini API key is not set. Please provide a valid API key.\")\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = GeminiLLM(\n",
    "        model_name=config['llm_config']['model_name'],\n",
    "        google_api_key=gemini_api_key,\n",
    "        model_params=config['llm_config']['model_params']\n",
    "    )\n",
    "    \n",
    "    # Initialize embedder\n",
    "    embedder = SentenceTransformerEmbeddings(model=config['embedder_config']['model_name'])\n",
    "    \n",
    "    # Configure text splitter\n",
    "    text_splitter_config = config['text_splitter_config']\n",
    "    \n",
    "    # Load data\n",
    "    df_path = os.path.join(script_dir, 'FILTERED_DATAFRAME.parquet')\n",
    "    df = pl.read_parquet(df_path)\n",
    "\n",
    "    # Convert 'date' column to string format (from YYYYMMDD to YYYY-MM-DD)\n",
    "    df = df.with_columns(pl.col('date').cast(pl.String))\n",
    "    df = df.with_columns(pl.col('date').str.strptime(pl.Date, format='%Y%m%d'))\n",
    "    df = df.with_columns(pl.col('date').dt.strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Create subset of the dataframe for testing\n",
    "    df = df.head(10)\n",
    "    \n",
    "    # Create the pipeline - use with statement to ensure proper resource management\n",
    "    # and to ensure the driver is closed after use\n",
    "    with neo4j.GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password)) as driver:\n",
    "        \n",
    "        # Initialize entity resolver\n",
    "        resolver = SpaCySemanticMatchResolver(  # Merge nodes with same label and similar textual properties\n",
    "            driver,\n",
    "            filter_query=None,  # \"WHERE (entity)-[:FROM_CHUNK]->(:Chunk)-[:FROM_DOCUMENT]->(doc:Document {id = 'docId'}\",  # Used to reduce the resolution scope to a specific document\n",
    "            resolve_properties=[\"name\"],  # Properties to use for resolution (default is \"name\")\n",
    "            similarity_threshold=0.8,  # The similarity threshold above which nodes are merged (default is 0.8). Higher threshold will result in less false positives, but may miss some matches. \n",
    "            spacy_model=\"en_core_web_lg\"  # spaCy model to use for resolution (default is \"en_core_web_lg\")\n",
    "        )\n",
    "\n",
    "        # Initialize the custom KG pipeline\n",
    "        kg_pipeline = CustomKGPipeline(\n",
    "            llm=llm,\n",
    "            driver=driver,\n",
    "            embedder=embedder,\n",
    "            schema_config=config['schema_config'],\n",
    "            prompt_template=config['prompt_template_config']['template'] if config['prompt_template_config'].get('use_default') == False else None,\n",
    "            text_splitter_config=text_splitter_config,\n",
    "            resolver=resolver,\n",
    "            examples_config=config['examples_config'],  # Use None if no examples are provided\n",
    "            on_error='RAISE',\n",
    "            batch_size=1000,\n",
    "            max_concurrency=5\n",
    "        )\n",
    "        \n",
    "        # Define metadata mapping (document properties additional to base field \n",
    "        # to dataframe columns)\n",
    "        metadata_mapping = {\n",
    "            \"source\": \"url\",\n",
    "            \"published_date\": \"date\"\n",
    "        }\n",
    "        \n",
    "        # Process the dataframe\n",
    "        results = await build_kg_from_df(\n",
    "            kg_pipeline=kg_pipeline,\n",
    "            df=df,\n",
    "            document_base_field='title',\n",
    "            text_column='full_text',\n",
    "            document_metadata_mapping=metadata_mapping,\n",
    "            document_id_column=None  # Use default document ID generation\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Asyncio event loop to run the main function in a Jupyter notebook\n",
    "results = await main()\n",
    "print(f\"Processed {len(results)} documents\")\n",
    "\n",
    "# # Asyncio event loop to run the main function in a script\n",
    "# if __name__ == \"__main__\":\n",
    "#     results = asyncio.run(main())\n",
    "#     print(f\"Processed {len(results)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5a267",
   "metadata": {},
   "source": [
    "Obviously, the examples provided have to be useful for the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67cb35f",
   "metadata": {},
   "source": [
    "# Entity Resolution Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOC is available.\n",
      "Resolving similar entities...\n",
      "Found 1008 similar entity pairs.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv(\"NEO4J_URI\"),\n",
    "    auth=(\"neo4j\", os.getenv(\"NEO4J_PASSWORD\"))\n",
    ")\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def get_embedding(text):\n",
    "    return model.encode(text).tolist()\n",
    "\n",
    "# List of relevant node labels for deduplication\n",
    "ENTITY_LABELS = [\"Event\", \"Actor\", \"Country\", \"ADM1\", \"Location\"]\n",
    "\n",
    "def get_all_entities():\n",
    "    query_template = \"\"\"\n",
    "    MATCH (n:{label})\n",
    "    RETURN elementId(n) AS id, labels(n)[0] AS label, n.name AS name, properties(n) AS properties\n",
    "\n",
    "    \"\"\"\n",
    "    all_entities = []\n",
    "    with driver.session() as session:\n",
    "        for label in ENTITY_LABELS:\n",
    "            result = session.run(query_template.format(label=label)).data()\n",
    "            all_entities.extend(result)\n",
    "    return all_entities\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    if vec1 is None or vec2 is None or len(vec1) == 0 or len(vec2) == 0:\n",
    "        return 0  # If either vector is None or empty, return 0 similarity\n",
    "    dot = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0\n",
    "\n",
    "def find_similar_entities(threshold=0.5):\n",
    "    entities = get_all_entities()\n",
    "    \n",
    "    # Compute embeddings\n",
    "    for entity in entities:\n",
    "        text = f\"Name: {entity['name']}\\n\"\n",
    "        for key, value in entity['properties'].items():\n",
    "            if key != 'name' and key != 'embedding' and value:\n",
    "                text += f\"{key}: {value}\\n\"\n",
    "        entity['embedding'] = get_embedding(text)\n",
    "    \n",
    "    # Find similar pairs\n",
    "    similar_pairs = []\n",
    "    for i, e1 in enumerate(entities):\n",
    "        for j, e2 in enumerate(entities[i + 1:], i + 1):\n",
    "            if e1['label'] != e2['label']:  # Only compare same types\n",
    "                continue\n",
    "            sim = cosine_similarity(e1['embedding'], e2['embedding'])\n",
    "            if sim > threshold:\n",
    "                similar_pairs.append({\n",
    "                    \"id1\": e1['id'],\n",
    "                    \"id2\": e2['id'],\n",
    "                    \"name1\": e1['name'],\n",
    "                    \"name2\": e2['name'],\n",
    "                    \"type1\": e1['properties'].get('type', e1['label']),  # Get type from properties or fall back to label\n",
    "                    \"type2\": e2['properties'].get('type', e2['label']),\n",
    "                    \"similarity\": sim\n",
    "                })\n",
    "    \n",
    "    # Create SAME_AS relationships\n",
    "    query = \"\"\"\n",
    "    MATCH (a), (b)\n",
    "    WHERE elementId(a) = $id1 AND elementId(b) = $id2\n",
    "    MERGE (a)-[:SAME_AS {similarity: $similarity}]->(b)\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        for pair in similar_pairs:\n",
    "            session.run(query, pair)\n",
    "    \n",
    "    return similar_pairs\n",
    "\n",
    "def merge_similar_nodes():\n",
    "    merge_query = \"\"\"\n",
    "    // Process one pair of nodes at a time to avoid conflicts\n",
    "    MATCH (n1)-[r:SAME_AS]->(n2)\n",
    "    WHERE n1 IS NOT NULL AND n2 IS NOT NULL\n",
    "    \n",
    "    // Copy properties from n2 to n1 if they don't exist in n1\n",
    "    WITH n1, n2, [key IN keys(n2) WHERE NOT key IN keys(n1)] AS newKeys\n",
    "    FOREACH (key IN newKeys | SET n1[key] = n2[key])\n",
    "    \n",
    "    // Get all outgoing relationships from n2 (except SAME_AS)\n",
    "    WITH n1, n2\n",
    "    OPTIONAL MATCH (n2)-[outRel]->(target)\n",
    "    WHERE target IS NOT NULL AND type(outRel) <> 'SAME_AS'\n",
    "    \n",
    "    // Create equivalent relationships from n1 if they don't already exist\n",
    "    WITH n1, n2, outRel, target, type(outRel) AS relType\n",
    "    WHERE NOT EXISTS((n1)-[:`${relType}`]->(target))\n",
    "    \n",
    "    // Create new relationship with the same properties\n",
    "    FOREACH (_ IN CASE WHEN outRel IS NOT NULL THEN [1] ELSE [] END |\n",
    "        CREATE (n1)-[newRel:`${relType}`]->(target)\n",
    "        SET newRel = properties(outRel)\n",
    "    )\n",
    "    \n",
    "    // Return the node pair for the next phase\n",
    "    WITH DISTINCT n1, n2\n",
    "    \n",
    "    // Handle incoming relationships\n",
    "    OPTIONAL MATCH (source)-[inRel]->(n2)\n",
    "    WHERE source IS NOT NULL AND source <> n1 AND type(inRel) <> 'SAME_AS'\n",
    "    \n",
    "    // Create equivalent relationships to n1 if they don't already exist\n",
    "    WITH n1, n2, inRel, source, type(inRel) AS relType\n",
    "    WHERE NOT EXISTS((source)-[:`${relType}`]->(n1))\n",
    "    \n",
    "    // Create new relationship with the same properties\n",
    "    FOREACH (_ IN CASE WHEN inRel IS NOT NULL THEN [1] ELSE [] END |\n",
    "        CREATE (source)-[newRel:`${relType}`]->(n1)\n",
    "        SET newRel = properties(inRel)\n",
    "    )\n",
    "    \n",
    "    // Return distinct pairs for deletion phase\n",
    "    WITH DISTINCT n1, n2\n",
    "    \n",
    "    // Delete the second node and all its relationships\n",
    "    DETACH DELETE n2\n",
    "    \n",
    "    RETURN count(n2) AS mergedCount\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            result = session.run(merge_query)\n",
    "            record = result.single()\n",
    "            return record[\"mergedCount\"] if record else 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error during node merging: {e}\")\n",
    "        return 0\n",
    "\n",
    "def check_apoc():\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            session.run(\"CALL apoc.help('create')\")\n",
    "            print(\"APOC is available.\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"APOC not available: {e}\")\n",
    "        return False\n",
    "\n",
    "# === MAIN EXECUTION ===\n",
    "check_apoc()\n",
    "print(\"Resolving similar entities...\")\n",
    "pairs = find_similar_entities().sort(by=\"similarity\", ascending=False)\n",
    "print(f\"Found {len(pairs)} similar entity pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be4205df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:52', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:204', 'name1': '727 cholera cases', 'name2': 'Cholera outbreak', 'type1': 'Disease Cases', 'type2': 'Disease Outbreak', 'similarity': np.float64(0.83766637758409)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:52', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:208', 'name1': '727 cholera cases', 'name2': 'cholera-related deaths and infections', 'type1': 'Disease Cases', 'type2': 'Disease Outbreak', 'similarity': np.float64(0.8441095024319051)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:184', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:192', 'name1': 'closure of main hospital', 'name2': 'Hospital', 'type1': 'Closure', 'type2': 'medical facility', 'similarity': np.float64(0.8070646261053283)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:204', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:208', 'name1': 'Cholera outbreak', 'name2': 'cholera-related deaths and infections', 'type1': 'Disease Outbreak', 'type2': 'Disease Outbreak', 'similarity': np.float64(0.8689937261945164)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:230', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:219', 'name1': 'Attack on Social Security Hospital', 'name2': 'Social Security Hospital', 'type1': 'Attack', 'type2': '__KGBuilder__', 'similarity': np.float64(0.8157245144110703)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:16', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:166', 'name1': 'UN migration agency', 'name2': 'UN representative', 'type1': 'international organization', 'type2': 'International Organization Official', 'similarity': np.float64(0.8120825545448764)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:25', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:50', 'name1': 'four other people', 'name2': '70 people', 'type1': 'civilian', 'type2': 'civilian', 'similarity': np.float64(0.8285402681777452)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:25', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:56', 'name1': 'four other people', 'name2': 'an adult', 'type1': 'civilian', 'type2': 'civilian', 'similarity': np.float64(0.8061995484551268)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:25', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:167', 'name1': 'four other people', 'name2': 'civilians', 'type1': 'civilian', 'type2': 'civilian', 'similarity': np.float64(0.8617455692357125)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:50', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:167', 'name1': '70 people', 'name2': 'civilians', 'type1': 'civilian', 'type2': 'civilian', 'similarity': np.float64(0.813746630545936)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:56', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:167', 'name1': 'an adult', 'name2': 'civilians', 'type1': 'civilian', 'type2': 'civilian', 'similarity': np.float64(0.8979506329599681)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:86', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:206', 'name1': 'army', 'name2': 'military', 'type1': 'military', 'type2': 'military', 'similarity': np.float64(0.9538029248541982)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:98', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:202', 'name1': 'Rapid Support Forces', 'name2': 'RSF', 'type1': 'paramilitary group', 'type2': 'paramilitary group', 'similarity': np.float64(0.8025413473063501)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:112', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:164', 'name1': 'WFP', 'name2': 'WHO', 'type1': 'International Organization', 'type2': 'International Organization', 'similarity': np.float64(0.8256183350773113)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:127', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:209', 'name1': 'Sudanese government', 'name2': 'Sudan', 'type1': 'government', 'type2': '__KGBuilder__', 'similarity': np.float64(0.8402078570175019)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:167', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:216', 'name1': 'civilians', 'name2': 'staff', 'type1': 'civilian', 'type2': 'civilian', 'similarity': np.float64(0.8001027096279615)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:190', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:210', 'name1': 'Sudan doctors union', 'name2': 'Sudan Doctors Network', 'type1': 'organization', 'type2': 'organization', 'similarity': np.float64(0.9221113834253754)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:192', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:221', 'name1': 'Hospital', 'name2': 'hospital', 'type1': 'medical facility', 'type2': '__KGBuilder__', 'similarity': np.float64(0.8978453321752393)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:209', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:207', 'name1': 'Sudan', 'name2': 'Khartoum', 'type1': '__KGBuilder__', 'type2': '__KGBuilder__', 'similarity': np.float64(0.8446088837777966)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:209', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:228', 'name1': 'Sudan', 'name2': 'Khartoum', 'type1': '__KGBuilder__', 'type2': '__KGBuilder__', 'similarity': np.float64(0.8284266815054331)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:207', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:228', 'name1': 'Khartoum', 'name2': 'Khartoum', 'type1': '__KGBuilder__', 'type2': '__KGBuilder__', 'similarity': np.float64(0.9344566927541319)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:55', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:160', 'name1': 'Al Koma', 'name2': 'al-Khowi', 'type1': '__KGBuilder__', 'type2': '__KGBuilder__', 'similarity': np.float64(0.858407431106972)}, {'id1': '4:47781cee-4592-4361-af19-475a2abd1ee7:220', 'id2': '4:47781cee-4592-4361-af19-475a2abd1ee7:221', 'name1': 'El Obeid Hospital', 'name2': 'hospital', 'type1': '__KGBuilder__', 'type2': '__KGBuilder__', 'similarity': np.float64(0.8266915880934651)}]\n"
     ]
    }
   ],
   "source": [
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge_similar_nodes()\n",
    "print(f\"Merged {merged} nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da5cd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gds = GraphDatabase.driver(\n",
    "    os.getenv(\"NEO4J_URI\"),\n",
    "    auth=(\n",
    "        \"neo4j\",\n",
    "        os.getenv(\"NEO4J_PASSWORD\")\n",
    "    )\n",
    ")\n",
    "\n",
    "client = genai.Client(api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c57305",
   "metadata": {},
   "source": [
    "### Node similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_similarity_query = \"\"\"\n",
    "CALL gds.nodeSimilarity.stream('amazonGraph')\n",
    "YIELD node1, node2, similarity as node_similarity\n",
    "WHERE 'Company' IN labels(gds.util.asNode(node1)) AND 'Company' IN labels(gds.util.asNode(node2))\n",
    "AND node_similarity < 1\n",
    "RETURN gds.util.asNode(node1).name AS Company1, gds.util.asNode(node2).name AS Company2, node_similarity\n",
    "ORDER BY node_similarity DESCENDING, Company1, Company2\n",
    "\"\"\"\n",
    "\n",
    "def results_to_df(query: str) -> pd.DataFrame:\n",
    "    results = gds.execute_query(query)[0]\n",
    "    df = pd.DataFrame(results, columns=results[0].keys())\n",
    "    return df\n",
    "\n",
    "df_node_similarity = results_to_df(node_similarity_query)\n",
    "print(df_node_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94f935",
   "metadata": {},
   "source": [
    "### Embeddings and Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb500d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_query = \"\"\"\n",
    "MATCH (c:Company)\n",
    "RETURN c, properties(c) as properties, id(c) as id\n",
    "\"\"\"\n",
    "\n",
    "def properties_to_text(node) -> str:\n",
    "    \"\"\"Given node, return string of all its properties\"\"\"\n",
    "    property_text = \"\"\n",
    "    properties = [p for p in node.get('properties').keys() if p != 'embedding']\n",
    "    for property_name in properties:\n",
    "        property_text += f\"{property_name}: {node.get('properties').get(property_name)}\\n\"\n",
    "    return property_text\n",
    "\n",
    "def add_node_embedding(node):\n",
    "    text = properties_to_text(node)\n",
    "    embedding = get_embedding(text) # Assuming get_embedding is defined elsewhere, likely from OpenAI as seen in previous context\n",
    "    add_embeddings_query = f\"\"\"\n",
    "    MATCH (n)\n",
    "    WHERE id(n) = {node.get('id')}\n",
    "    SET n.embedding = {embedding}\n",
    "    \"\"\"\n",
    "    gds.execute_query(add_embeddings_query)\n",
    "    \n",
    "results = gds.execute_query(companies_query)[0]\n",
    "for r in results:\n",
    "    add_node_embedding(r)\n",
    "\n",
    "cosine_similarity_query = \"\"\"\n",
    "// Cosine Similarity\n",
    "MATCH (c1:Company), (c2:Company)\n",
    "WHERE id(c1) < id(c2)\n",
    "WITH c1, c2, gds.similarity.cosine(c1.embedding, c2.embedding) AS cosine_similarity\n",
    "WHERE cosine_similarity < 1\n",
    "RETURN c1.name AS Company1, c2.name AS Company2, cosine_similarity\n",
    "ORDER BY cosine_similarity DESC\n",
    "\"\"\"\n",
    "\n",
    "df_cosine_similarity = results_to_df(cosine_similarity_query)\n",
    "print(df_cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6832d7",
   "metadata": {},
   "source": [
    "### Combine similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e415c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(df_cosine_similarity, df_node_similarity, how='inner', on=(\"Company1\", \"Company2\"))\n",
    "combined_df[\"combined_score\"] = combined_df[\"node_similarity\"] * combined_df[\"cosine_similarity\"]\n",
    "combined_df.sort_values(by=\"combined_score\", ascending=False, inplace=True)\n",
    "\n",
    "selected_df = combined_df[[\"Company1\", \"Company2\", \"combined_score\", \"node_similarity\", \"cosine_similarity\"]]\n",
    "print(selected_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb28fec",
   "metadata": {},
   "source": [
    "### Create SAME_AS relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e661965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_same_as_relationship(df, column_name):\n",
    "    # Iterate over the DataFrame rows\n",
    "    for _, row in df.iterrows():\n",
    "        node1 = row[column_name + '1']\n",
    "        node2 = row[column_name + '2']\n",
    "\n",
    "        # Run Cypher query to create 'SAME_AS' relationship\n",
    "        score = row[\"combined_score\"]\n",
    "        if score > 0.20:\n",
    "            query = f\"MATCH (n1), (n2) WHERE n1.name = '{node1}' AND n2.name = '{node2}' CREATE (n1)-[:SAME_AS]->(n2)\"\n",
    "            gds.execute_query(query)\n",
    "\n",
    "create_same_as_relationship(selected_df, \"Company\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52dbed9",
   "metadata": {},
   "source": [
    "### Merge nodes with SAME_AS relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_query = \"\"\"\n",
    "MATCH (n1)-[r:SAME_AS]->(n2)\n",
    "WITH n1, n2, collect(r) as relsToDel\n",
    "\n",
    "FOREACH (rel IN relsToDel | DELETE rel)\n",
    "WITH collect(DISTINCT n1) + collect(DISTINCT n2) AS nodesToMerge\n",
    "\n",
    "UNWIND nodesToMerge AS node\n",
    "\n",
    "WITH collect(DISTINCT node) AS uniqueNodesToMerge\n",
    "CALL apoc.refactor.mergeNodes(uniqueNodesToMerge, {mergeRels:true}) YIELD node\n",
    "RETURN node\n",
    "\"\"\"\n",
    "\n",
    "gds.execute_query(merge_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".v_un",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
